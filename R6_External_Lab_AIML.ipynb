{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R6_External_Lab_AIML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYk8NG3yOIT9",
        "colab_type": "text"
      },
      "source": [
        "### A MNIST-like fashion product database\n",
        "\n",
        "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFO6PuxzOIT_",
        "colab_type": "text"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAM-2X5HRkgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OFY3V9rTxNq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a21a2de-68a1-4d51-f130-a8d9f9a93de8"
      },
      "source": [
        "pip install tensorflow-gpu"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/9a/6a3985daf15d0b87b1ef3c499293cf0889cd294223a6ca28b9529770b29e/tensorflow_gpu-2.0.0-cp27-cp27mu-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 35kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.2.2 in /tensorflow-2.1.0/python2.7 (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /tensorflow-2.1.0/python2.7 (from tensorflow-gpu) (1.25.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /tensorflow-2.1.0/python2.7 (from tensorflow-gpu) (1.16.5)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/3d/993131c622ae34f9401a81526853f2310a4834bd042420a7982fb5bc5fd0/tensorboard-2.0.2-py2-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 44.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /tensorflow-2.1.0/python2.7 (from tensorflow-gpu) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /tensorflow-2.1.0/python2.7 (from tensorflow-gpu) (3.11.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /tensorflow-2.1.0/python2.7 (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: backports.weakref>=1.0rc1; python_version < \"3.4\" in /tensorflow-2.1.0/python2.7 (from tensorflow-gpu) (1.0.post1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-2.1.0/python2.7 (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied: mock>=2.0.0 in /tensorflow-2.1.0/python2.7 (from tensorflow-gpu) (3.0.5)\n",
            "Requirement already satisfied: wheel in /tensorflow-2.1.0/python2.7 (from tensorflow-gpu) (0.33.6)\n",
            "Requirement already satisfied: functools32>=3.2.3 in /tensorflow-2.1.0/python2.7 (from tensorflow-gpu) (3.2.3.post2)\n",
            "Requirement already satisfied: six>=1.10.0 in /tensorflow-2.1.0/python2.7 (from tensorflow-gpu) (1.13.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /tensorflow-2.1.0/python2.7 (from tensorflow-gpu) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /tensorflow-2.1.0/python2.7 (from tensorflow-gpu) (2.3.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /tensorflow-2.1.0/python2.7 (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /tensorflow-2.1.0/python2.7 (from tensorflow-gpu) (0.1.8)\n",
            "Requirement already satisfied: enum34>=1.1.6; python_version < \"3.4\" in /tensorflow-2.1.0/python2.7 (from tensorflow-gpu) (1.1.6)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 45.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /tensorflow-2.1.0/python2.7 (from tensorflow-gpu) (0.8.1)\n",
            "Requirement already satisfied: futures>=2.2.0; python_version < \"3.2\" in /tensorflow-2.1.0/python2.7 (from grpcio>=1.8.6->tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /tensorflow-2.1.0/python2.7 (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (42.0.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /tensorflow-2.1.0/python2.7 (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /tensorflow-2.1.0/python2.7 (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.16.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /tensorflow-2.1.0/python2.7 (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.9.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /tensorflow-2.1.0/python2.7 (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.22.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /tensorflow-2.1.0/python2.7 (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: h5py in /tensorflow-2.1.0/python2.7 (from keras-applications>=1.0.8->tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /tensorflow-2.1.0/python2.7 (from mock>=2.0.0->tensorflow-gpu) (1.0.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /tensorflow-2.1.0/python2.7 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /tensorflow-2.1.0/python2.7 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.2.7)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /tensorflow-2.1.0/python2.7 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /tensorflow-2.1.0/python2.7 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (4.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python2.7 (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.25.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python2.7 (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python2.7 (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python2.7 (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /tensorflow-2.1.0/python2.7 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /tensorflow-2.1.0/python2.7 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.8)\n",
            "\u001b[31mERROR: tensorflow 2.1.0rc1 has requirement tensorboard<2.2.0,>=2.1.0, but you'll have tensorboard 2.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.1.0rc1 has requirement tensorflow-estimator<2.2.0,>=2.1.0rc0, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 2.1.0\n",
            "    Uninstalling tensorboard-2.1.0:\n",
            "      Successfully uninstalled tensorboard-2.1.0\n",
            "  Found existing installation: tensorflow-estimator 2.1.0\n",
            "    Uninstalling tensorflow-estimator-2.1.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
            "Successfully installed tensorboard-2.0.2 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_core",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFDXDClOO89D",
        "colab_type": "code",
        "outputId": "7f8f1a03-6d4a-4cc9-e387-69efa7258524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "#From tensorflow v2.0 onwards, Eager Execution will be enabled by default"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyCBNLm3gbVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efNjNImfOIUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcoZBStrOIUQ",
        "colab_type": "text"
      },
      "source": [
        "### Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJym4ZCKgyLl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "efbc9797-1aa5-4d6b-a21f-ddb325825a6a"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbiHj5YPOIUc",
        "colab_type": "code",
        "outputId": "f07475d1-7e88-42d7-dc87-a6a2d6fddf40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(test_labels[0:5])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 2 1 1 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVdS-lfuRJ2G",
        "colab_type": "code",
        "outputId": "7ef0419e-14a8-4b62-eb27-0abf74b44fc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU7DY3W0ROEH",
        "colab_type": "code",
        "outputId": "027b7c10-1fe5-4138-ed5e-effa48a74e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_labels.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJBDBgYTRS6u",
        "colab_type": "code",
        "outputId": "0ecd9a9b-298e-4898-e94e-880ccecbd26a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_images.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53FKEZJDRXts",
        "colab_type": "code",
        "outputId": "2ac47eb9-3316-4a12-ba79-c3c890bab618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_labels.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQN2aC-WR19j",
        "colab_type": "code",
        "outputId": "721ac588-4aa6-412f-eaa6-8d18b84fb530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_images.dtype"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7704haNS6re",
        "colab_type": "code",
        "outputId": "d5391c31-ad17-4f65-ad25-00f6e49e9005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(train_labels.shape)\n",
        "print('First 5 examples are: ', train_labels[0:2])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n",
            "('First 5 examples are: ', array([9, 0], dtype=uint8))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW9zmRtQbPx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDAYzkwyOIUj",
        "colab_type": "text"
      },
      "source": [
        "### Convert both training and testing labels into one-hot vectors.\n",
        "\n",
        "**Hint:** check **tf.keras.utils.to_categorical()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBlfYlANOIUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels_OH = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n",
        "test_labels_OH = tf.keras.utils.to_categorical(test_labels, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKJWqCRZTXUK",
        "colab_type": "text"
      },
      "source": [
        "###Print shape and some values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "RHV3b9mzOIUq",
        "colab_type": "code",
        "outputId": "d6570757-2297-4899-aef8-1cad8b52d838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "print(train_labels_OH.shape)\n",
        "print('First 5 examples now are: ', train_labels_OH[0:5])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "('First 5 examples now are: ', array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsWk3MmVVFpv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "68b35dea-b025-4e63-9611-eb094cc1918f"
      },
      "source": [
        "print(test_labels_OH.shape)\n",
        "print('First 5 examples now are: ', test_labels_OH[0:5])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 10)\n",
            "('First 5 examples now are: ', array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-_uNtTUcY6U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "9d078067-0643-4615-8f7b-2f36d270b4b3"
      },
      "source": [
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)\n",
        "print(train_labels_OH.shape)\n",
        "print(test_labels_OH.shape)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n",
            "(60000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwhQ8e7VOIUw",
        "colab_type": "text"
      },
      "source": [
        "### Visualize the data\n",
        "\n",
        "Plot first 10 images in the triaining set and their labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMSKqe-mVfc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvDML2OoOIUx",
        "colab_type": "code",
        "outputId": "91ab8d74-e35f-400d-a4e9-906d75a9125a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[1])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAD8CAYAAAAfZJO2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJiJJUxITkaQpiYlI0v4dKA+LCXuBt6AAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSCSzX9yWBUW",
        "colab_type": "text"
      },
      "source": [
        "Scale these values to a range of 0 to 1 before feeding them to the neural network model. To do so, divide the values by 255. It's important that the *training set* and the *testing set* be preprocessed in the same way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VJ3hiajV5K0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TMvcX_FWNp0",
        "colab_type": "code",
        "outputId": "5e6f6c7f-8ede-466a-8671-911f57e58540",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(10):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAADuCAYAAADRE7iBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH9q2D85kMGi",
        "colab_type": "code",
        "outputId": "5cd6825d-7973-4387-9b6e-264c76c64a52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "print('Before datatype')\n",
        "print(train_images.dtype)\n",
        "print(train_labels.dtype)\n",
        "print(test_images.dtype)\n",
        "print(test_labels.dtype)\n",
        "print(train_labels_OH.dtype)\n",
        "print(test_labels_OH.dtype)\n",
        "train_images =np.array(train_images).astype('float32')\n",
        "train_labels = np.array(train_labels).astype('float32')\n",
        "test_images =np.array(test_images).astype('float32')\n",
        "test_labels = np.array(test_labels).astype('float32')\n",
        "train_labels_OH =np.array(test_images).astype('float32')\n",
        "test_labels_OH = np.array(test_labels).astype('float32')\n",
        "print('After datatype')\n",
        "print(train_images.dtype)\n",
        "print(train_labels.dtype)\n",
        "print(test_images.dtype)\n",
        "print(test_labels.dtype)\n",
        "print(train_labels_OH.dtype)\n",
        "print(test_labels_OH.dtype)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before datatype\n",
            "float64\n",
            "uint8\n",
            "float64\n",
            "uint8\n",
            "float32\n",
            "float32\n",
            "After datatype\n",
            "float32\n",
            "float32\n",
            "float32\n",
            "float32\n",
            "float32\n",
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4TbJGeSOIU4",
        "colab_type": "text"
      },
      "source": [
        "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_U0B-m9qSNr",
        "colab_type": "code",
        "outputId": "805f5fcb-5f11-4b48-93b2-92026440fcc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSPs_Xylyxg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "# Add Dense Layer which provides 10 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc1Mit84m2Py",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Comile the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hQpLv3aOIU_",
        "colab_type": "text"
      },
      "source": [
        "### Execute the model using model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDCmAhp3zeWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "231220cb-319d-4268-84da-5358606be37e"
      },
      "source": [
        "train_images.shape[0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O59C_-IgOIVB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf66e6b5-61c0-4334-e574-00fb44b9d88c"
      },
      "source": [
        "model.fit(train_images, train_labels_OH, validation_data=(test_images, test_labels_OH), epochs=50,\n",
        "          batch_size = train_images.shape[0])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 1s 17us/sample - loss: 2.4272 - accuracy: 0.1350 - val_loss: 2.3778 - val_accuracy: 0.1674\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 2.3743 - accuracy: 0.1699 - val_loss: 2.3337 - val_accuracy: 0.1979\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 2.3302 - accuracy: 0.2000 - val_loss: 2.2957 - val_accuracy: 0.2162\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 2.2921 - accuracy: 0.2187 - val_loss: 2.2621 - val_accuracy: 0.2278\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 2.2584 - accuracy: 0.2306 - val_loss: 2.2319 - val_accuracy: 0.2365\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2.2281 - accuracy: 0.2405 - val_loss: 2.2043 - val_accuracy: 0.2455\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 2.2005 - accuracy: 0.2504 - val_loss: 2.1789 - val_accuracy: 0.2538\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 2.1750 - accuracy: 0.2582 - val_loss: 2.1553 - val_accuracy: 0.2646\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 2.1513 - accuracy: 0.2666 - val_loss: 2.1331 - val_accuracy: 0.2722\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 2.1291 - accuracy: 0.2758 - val_loss: 2.1123 - val_accuracy: 0.2829\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 2.1082 - accuracy: 0.2851 - val_loss: 2.0925 - val_accuracy: 0.2929\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 2.0884 - accuracy: 0.2950 - val_loss: 2.0737 - val_accuracy: 0.3024\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 2.0695 - accuracy: 0.3051 - val_loss: 2.0558 - val_accuracy: 0.3128\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 2.0515 - accuracy: 0.3143 - val_loss: 2.0385 - val_accuracy: 0.3216\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 2.0342 - accuracy: 0.3237 - val_loss: 2.0220 - val_accuracy: 0.3315\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 2.0175 - accuracy: 0.3322 - val_loss: 2.0060 - val_accuracy: 0.3376\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 2.0014 - accuracy: 0.3414 - val_loss: 1.9905 - val_accuracy: 0.3481\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.9859 - accuracy: 0.3514 - val_loss: 1.9755 - val_accuracy: 0.3567\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.9708 - accuracy: 0.3604 - val_loss: 1.9609 - val_accuracy: 0.3651\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.9562 - accuracy: 0.3685 - val_loss: 1.9467 - val_accuracy: 0.3718\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.9419 - accuracy: 0.3766 - val_loss: 1.9329 - val_accuracy: 0.3778\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.9280 - accuracy: 0.3842 - val_loss: 1.9194 - val_accuracy: 0.3862\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.9144 - accuracy: 0.3923 - val_loss: 1.9063 - val_accuracy: 0.3948\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.9012 - accuracy: 0.4001 - val_loss: 1.8934 - val_accuracy: 0.4006\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.8882 - accuracy: 0.4079 - val_loss: 1.8808 - val_accuracy: 0.4078\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.8755 - accuracy: 0.4148 - val_loss: 1.8684 - val_accuracy: 0.4171\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.8631 - accuracy: 0.4215 - val_loss: 1.8563 - val_accuracy: 0.4241\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 1.8509 - accuracy: 0.4284 - val_loss: 1.8445 - val_accuracy: 0.4293\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.8390 - accuracy: 0.4344 - val_loss: 1.8329 - val_accuracy: 0.4360\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.8273 - accuracy: 0.4407 - val_loss: 1.8215 - val_accuracy: 0.4423\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.8159 - accuracy: 0.4472 - val_loss: 1.8103 - val_accuracy: 0.4481\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.8046 - accuracy: 0.4531 - val_loss: 1.7993 - val_accuracy: 0.4542\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.7935 - accuracy: 0.4593 - val_loss: 1.7886 - val_accuracy: 0.4606\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.7827 - accuracy: 0.4646 - val_loss: 1.7780 - val_accuracy: 0.4655\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.7720 - accuracy: 0.4700 - val_loss: 1.7676 - val_accuracy: 0.4709\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.7616 - accuracy: 0.4752 - val_loss: 1.7574 - val_accuracy: 0.4748\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.7513 - accuracy: 0.4799 - val_loss: 1.7473 - val_accuracy: 0.4818\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.7412 - accuracy: 0.4853 - val_loss: 1.7375 - val_accuracy: 0.4860\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.7312 - accuracy: 0.4899 - val_loss: 1.7278 - val_accuracy: 0.4900\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.7215 - accuracy: 0.4954 - val_loss: 1.7183 - val_accuracy: 0.4953\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.7119 - accuracy: 0.4999 - val_loss: 1.7089 - val_accuracy: 0.4987\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.7024 - accuracy: 0.5044 - val_loss: 1.6997 - val_accuracy: 0.5028\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.6931 - accuracy: 0.5086 - val_loss: 1.6906 - val_accuracy: 0.5071\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.6840 - accuracy: 0.5125 - val_loss: 1.6817 - val_accuracy: 0.5111\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.6750 - accuracy: 0.5174 - val_loss: 1.6729 - val_accuracy: 0.5148\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.6662 - accuracy: 0.5213 - val_loss: 1.6643 - val_accuracy: 0.5177\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.6575 - accuracy: 0.5254 - val_loss: 1.6558 - val_accuracy: 0.5212\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.6490 - accuracy: 0.5290 - val_loss: 1.6475 - val_accuracy: 0.5257\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.6405 - accuracy: 0.5327 - val_loss: 1.6393 - val_accuracy: 0.5296\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 1.6323 - accuracy: 0.5365 - val_loss: 1.6312 - val_accuracy: 0.5336\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f558f0158d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcsUUsxTeGt7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "e95ae124-29f3-4713-9953-fc3c339b7bc8"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_4 (Reshape)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdzDtGwDOIVF",
        "colab_type": "text"
      },
      "source": [
        "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kndfpdidOIVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize Sequential model\n",
        "model1 = tf.keras.models.Sequential()\n",
        "\n",
        "# Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model1.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "# Normalize the data\n",
        "model1.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "# Add Dense Layer which provides 10 Outputs after applying softmax\n",
        "model1.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfn87jP0S0xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Comile the model\n",
        "model1.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwk3T5LJOIVN",
        "colab_type": "text"
      },
      "source": [
        "### Execute the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNLR8tcBOIVP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c6f0f2c3-382c-4918-e7f2-089535dabb7f"
      },
      "source": [
        "model1.fit(train_images, train_labels_OH, validation_data=(test_images, test_labels_OH), epochs=50,\n",
        "          batch_size = train_images.shape[0])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.8943 - accuracy: 0.6946 - val_loss: 1.3707 - val_accuracy: 0.6495\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8892 - accuracy: 0.6962 - val_loss: 1.3629 - val_accuracy: 0.6517\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 0.8842 - accuracy: 0.6978 - val_loss: 1.3551 - val_accuracy: 0.6541\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8794 - accuracy: 0.6994 - val_loss: 1.3475 - val_accuracy: 0.6567\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8747 - accuracy: 0.7009 - val_loss: 1.3399 - val_accuracy: 0.6583\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8702 - accuracy: 0.7021 - val_loss: 1.3325 - val_accuracy: 0.6602\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8658 - accuracy: 0.7035 - val_loss: 1.3252 - val_accuracy: 0.6617\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8615 - accuracy: 0.7048 - val_loss: 1.3180 - val_accuracy: 0.6638\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8573 - accuracy: 0.7061 - val_loss: 1.3108 - val_accuracy: 0.6653\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8533 - accuracy: 0.7074 - val_loss: 1.3038 - val_accuracy: 0.6675\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8493 - accuracy: 0.7090 - val_loss: 1.2969 - val_accuracy: 0.6696\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8455 - accuracy: 0.7102 - val_loss: 1.2900 - val_accuracy: 0.6713\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8417 - accuracy: 0.7117 - val_loss: 1.2832 - val_accuracy: 0.6725\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8380 - accuracy: 0.7129 - val_loss: 1.2765 - val_accuracy: 0.6742\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8345 - accuracy: 0.7143 - val_loss: 1.2699 - val_accuracy: 0.6753\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8310 - accuracy: 0.7160 - val_loss: 1.2634 - val_accuracy: 0.6774\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8276 - accuracy: 0.7171 - val_loss: 1.2570 - val_accuracy: 0.6789\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8242 - accuracy: 0.7181 - val_loss: 1.2506 - val_accuracy: 0.6807\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8210 - accuracy: 0.7193 - val_loss: 1.2443 - val_accuracy: 0.6823\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8178 - accuracy: 0.7204 - val_loss: 1.2380 - val_accuracy: 0.6837\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8147 - accuracy: 0.7215 - val_loss: 1.2319 - val_accuracy: 0.6855\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8116 - accuracy: 0.7226 - val_loss: 1.2258 - val_accuracy: 0.6865\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8086 - accuracy: 0.7236 - val_loss: 1.2197 - val_accuracy: 0.6879\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8057 - accuracy: 0.7246 - val_loss: 1.2138 - val_accuracy: 0.6896\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8028 - accuracy: 0.7257 - val_loss: 1.2079 - val_accuracy: 0.6910\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8000 - accuracy: 0.7266 - val_loss: 1.2020 - val_accuracy: 0.6918\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7973 - accuracy: 0.7275 - val_loss: 1.1963 - val_accuracy: 0.6934\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7946 - accuracy: 0.7285 - val_loss: 1.1906 - val_accuracy: 0.6938\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7920 - accuracy: 0.7296 - val_loss: 1.1849 - val_accuracy: 0.6953\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7894 - accuracy: 0.7307 - val_loss: 1.1793 - val_accuracy: 0.6964\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7868 - accuracy: 0.7316 - val_loss: 1.1738 - val_accuracy: 0.6977\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7843 - accuracy: 0.7326 - val_loss: 1.1683 - val_accuracy: 0.6995\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7819 - accuracy: 0.7333 - val_loss: 1.1628 - val_accuracy: 0.7003\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7795 - accuracy: 0.7340 - val_loss: 1.1575 - val_accuracy: 0.7018\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7771 - accuracy: 0.7346 - val_loss: 1.1521 - val_accuracy: 0.7029\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7748 - accuracy: 0.7355 - val_loss: 1.1469 - val_accuracy: 0.7044\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7725 - accuracy: 0.7364 - val_loss: 1.1416 - val_accuracy: 0.7054\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7703 - accuracy: 0.7372 - val_loss: 1.1365 - val_accuracy: 0.7073\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7681 - accuracy: 0.7380 - val_loss: 1.1313 - val_accuracy: 0.7082\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7659 - accuracy: 0.7387 - val_loss: 1.1263 - val_accuracy: 0.7092\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7638 - accuracy: 0.7397 - val_loss: 1.1212 - val_accuracy: 0.7100\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7617 - accuracy: 0.7403 - val_loss: 1.1163 - val_accuracy: 0.7114\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7597 - accuracy: 0.7410 - val_loss: 1.1113 - val_accuracy: 0.7125\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7576 - accuracy: 0.7416 - val_loss: 1.1064 - val_accuracy: 0.7142\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7556 - accuracy: 0.7423 - val_loss: 1.1016 - val_accuracy: 0.7149\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7537 - accuracy: 0.7430 - val_loss: 1.0968 - val_accuracy: 0.7153\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7517 - accuracy: 0.7438 - val_loss: 1.0921 - val_accuracy: 0.7169\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7498 - accuracy: 0.7445 - val_loss: 1.0873 - val_accuracy: 0.7177\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7480 - accuracy: 0.7452 - val_loss: 1.0827 - val_accuracy: 0.7190\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.7461 - accuracy: 0.7459 - val_loss: 1.0781 - val_accuracy: 0.7195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f558c1b4e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oXmXCkeeA7z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "7a778ca1-68f6-4ed7-b87e-d0feecc4ce22"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_3 (Reshape)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 10,986\n",
            "Trainable params: 9,418\n",
            "Non-trainable params: 1,568\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py-KwkmjOIVU",
        "colab_type": "text"
      },
      "source": [
        "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCiAHT7rf0XH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8e63ad5-a95b-40ca-cbf3-3d57e4679c80"
      },
      "source": [
        "keras.optimizers.SGD(learning_rate=0.01)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD at 0x7f558e926d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu8e5PZIfFyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize Sequential model\n",
        "model2 = tf.keras.models.Sequential()\n",
        "\n",
        "# Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model2.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "# Normalize the data\n",
        "model2.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "# Add Dense Layer which provides 10 Outputs after applying softmax\n",
        "model2.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7-8TA8UfNyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Comile the model\n",
        "model2.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLo_93qofcFj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9a06b59b-a1a7-4239-db2f-07dc0d9f62f3"
      },
      "source": [
        "#Execute the model\n",
        "model2.fit(train_images, train_labels_OH, validation_data=(test_images, test_labels_OH), epochs=50,\n",
        "          batch_size = train_images.shape[0])"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 3.2814 - accuracy: 0.0495 - val_loss: 2.4223 - val_accuracy: 0.1078\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 2.9189 - accuracy: 0.0741 - val_loss: 2.3144 - val_accuracy: 0.1484\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 2.6161 - accuracy: 0.1095 - val_loss: 2.2267 - val_accuracy: 0.1863\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 2.3646 - accuracy: 0.1590 - val_loss: 2.1543 - val_accuracy: 0.2199\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 2.1566 - accuracy: 0.2158 - val_loss: 2.0937 - val_accuracy: 0.2466\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.9854 - accuracy: 0.2727 - val_loss: 2.0421 - val_accuracy: 0.2785\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.8449 - accuracy: 0.3251 - val_loss: 1.9977 - val_accuracy: 0.3183\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.7295 - accuracy: 0.3734 - val_loss: 1.9589 - val_accuracy: 0.3571\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.6344 - accuracy: 0.4148 - val_loss: 1.9246 - val_accuracy: 0.3930\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.5552 - accuracy: 0.4488 - val_loss: 1.8939 - val_accuracy: 0.4192\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.4888 - accuracy: 0.4790 - val_loss: 1.8661 - val_accuracy: 0.4398\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.4323 - accuracy: 0.5037 - val_loss: 1.8408 - val_accuracy: 0.4605\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.3838 - accuracy: 0.5249 - val_loss: 1.8174 - val_accuracy: 0.4751\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.3417 - accuracy: 0.5415 - val_loss: 1.7958 - val_accuracy: 0.4907\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.3048 - accuracy: 0.5552 - val_loss: 1.7755 - val_accuracy: 0.5041\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.2722 - accuracy: 0.5684 - val_loss: 1.7564 - val_accuracy: 0.5166\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.2431 - accuracy: 0.5786 - val_loss: 1.7383 - val_accuracy: 0.5254\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.2170 - accuracy: 0.5873 - val_loss: 1.7212 - val_accuracy: 0.5353\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1933 - accuracy: 0.5956 - val_loss: 1.7048 - val_accuracy: 0.5441\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1718 - accuracy: 0.6032 - val_loss: 1.6892 - val_accuracy: 0.5516\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1521 - accuracy: 0.6102 - val_loss: 1.6742 - val_accuracy: 0.5571\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1340 - accuracy: 0.6164 - val_loss: 1.6598 - val_accuracy: 0.5634\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1172 - accuracy: 0.6223 - val_loss: 1.6459 - val_accuracy: 0.5705\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1017 - accuracy: 0.6276 - val_loss: 1.6324 - val_accuracy: 0.5766\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0872 - accuracy: 0.6323 - val_loss: 1.6194 - val_accuracy: 0.5826\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0736 - accuracy: 0.6361 - val_loss: 1.6068 - val_accuracy: 0.5879\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0609 - accuracy: 0.6403 - val_loss: 1.5946 - val_accuracy: 0.5920\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0490 - accuracy: 0.6441 - val_loss: 1.5827 - val_accuracy: 0.5968\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0377 - accuracy: 0.6477 - val_loss: 1.5711 - val_accuracy: 0.6021\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0270 - accuracy: 0.6509 - val_loss: 1.5598 - val_accuracy: 0.6044\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0169 - accuracy: 0.6542 - val_loss: 1.5488 - val_accuracy: 0.6075\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0073 - accuracy: 0.6574 - val_loss: 1.5381 - val_accuracy: 0.6110\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9982 - accuracy: 0.6606 - val_loss: 1.5276 - val_accuracy: 0.6157\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9894 - accuracy: 0.6636 - val_loss: 1.5174 - val_accuracy: 0.6194\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9811 - accuracy: 0.6662 - val_loss: 1.5073 - val_accuracy: 0.6228\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9732 - accuracy: 0.6686 - val_loss: 1.4975 - val_accuracy: 0.6276\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9655 - accuracy: 0.6708 - val_loss: 1.4879 - val_accuracy: 0.6310\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9582 - accuracy: 0.6732 - val_loss: 1.4784 - val_accuracy: 0.6336\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9512 - accuracy: 0.6758 - val_loss: 1.4691 - val_accuracy: 0.6372\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9444 - accuracy: 0.6779 - val_loss: 1.4600 - val_accuracy: 0.6408\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9379 - accuracy: 0.6804 - val_loss: 1.4511 - val_accuracy: 0.6435\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9316 - accuracy: 0.6822 - val_loss: 1.4423 - val_accuracy: 0.6464\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9256 - accuracy: 0.6840 - val_loss: 1.4336 - val_accuracy: 0.6490\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9197 - accuracy: 0.6861 - val_loss: 1.4251 - val_accuracy: 0.6508\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9141 - accuracy: 0.6880 - val_loss: 1.4168 - val_accuracy: 0.6528\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9086 - accuracy: 0.6898 - val_loss: 1.4085 - val_accuracy: 0.6550\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9033 - accuracy: 0.6919 - val_loss: 1.4004 - val_accuracy: 0.6563\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8982 - accuracy: 0.6934 - val_loss: 1.3924 - val_accuracy: 0.6594\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8932 - accuracy: 0.6953 - val_loss: 1.3846 - val_accuracy: 0.6616\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8884 - accuracy: 0.6970 - val_loss: 1.3768 - val_accuracy: 0.6642\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f558b13ead0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdH1FysPfhdp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "d5a1263c-e1fe-4c99-e7cb-5bb9f2d6c969"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_10 (Reshape)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 10,986\n",
            "Trainable params: 9,418\n",
            "Non-trainable params: 1,568\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CSqKvpOIVk",
        "colab_type": "text"
      },
      "source": [
        "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and sigmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGAad54JOIVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize Sequential model\n",
        "model3 = tf.keras.models.Sequential()\n",
        "\n",
        "# Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model3.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "# Normalize the data\n",
        "model3.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "# Hidden layers\n",
        "model3.add(tf.keras.layers.Dense(100, activation='sigmoid', name='Layer_1'))\n",
        "model3.add(tf.keras.layers.Dense(100, activation='sigmoid', name='Layer_2'))\n",
        "model3.add(tf.keras.layers.Dense(10, activation='sigmoid', name='Layer_3'))\n",
        "\n",
        "#Output layer which provides 10 Outputs after applying softmax\n",
        "model3.add(tf.keras.layers.Dense(10, activation='softmax', name='Output'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiP7IL52OIVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile the model with sgd optimizer learning_rate 0.03\n",
        "model3.compile(optimizer=keras.optimizers.SGD(learning_rate=0.03), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfFGmbZLOIV5",
        "colab_type": "text"
      },
      "source": [
        "### Run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIkbMEN5OIV7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3427fbfd-3499-4b81-d092-e7c61787ca19"
      },
      "source": [
        "#Execute the model\n",
        "model3.fit(train_images, train_labels_OH, validation_data=(test_images, test_labels_OH), epochs=50,\n",
        "          batch_size = train_images.shape[0])"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 3s 48us/sample - loss: 2.3985 - accuracy: 0.1000 - val_loss: 2.3929 - val_accuracy: 0.1000\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3957 - accuracy: 0.1000 - val_loss: 2.3903 - val_accuracy: 0.1000\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3929 - accuracy: 0.1000 - val_loss: 2.3878 - val_accuracy: 0.1000\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3902 - accuracy: 0.1000 - val_loss: 2.3853 - val_accuracy: 0.1000\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3876 - accuracy: 0.1000 - val_loss: 2.3830 - val_accuracy: 0.1000\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3850 - accuracy: 0.1000 - val_loss: 2.3807 - val_accuracy: 0.1000\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3826 - accuracy: 0.1000 - val_loss: 2.3785 - val_accuracy: 0.1000\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3802 - accuracy: 0.1000 - val_loss: 2.3763 - val_accuracy: 0.1000\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3779 - accuracy: 0.1000 - val_loss: 2.3743 - val_accuracy: 0.1000\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 2.3757 - accuracy: 0.1000 - val_loss: 2.3723 - val_accuracy: 0.1000\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3735 - accuracy: 0.1000 - val_loss: 2.3703 - val_accuracy: 0.1000\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3714 - accuracy: 0.1000 - val_loss: 2.3684 - val_accuracy: 0.1000\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3694 - accuracy: 0.1000 - val_loss: 2.3666 - val_accuracy: 0.1000\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3674 - accuracy: 0.1000 - val_loss: 2.3649 - val_accuracy: 0.1000\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3655 - accuracy: 0.1000 - val_loss: 2.3631 - val_accuracy: 0.1000\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3637 - accuracy: 0.1000 - val_loss: 2.3615 - val_accuracy: 0.1000\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3619 - accuracy: 0.1000 - val_loss: 2.3599 - val_accuracy: 0.1000\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 2.3601 - accuracy: 0.1000 - val_loss: 2.3583 - val_accuracy: 0.1000\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 2.3584 - accuracy: 0.1000 - val_loss: 2.3568 - val_accuracy: 0.1000\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 2.3568 - accuracy: 0.1000 - val_loss: 2.3553 - val_accuracy: 0.1000\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3551 - accuracy: 0.1000 - val_loss: 2.3539 - val_accuracy: 0.1000\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 2.3536 - accuracy: 0.1000 - val_loss: 2.3525 - val_accuracy: 0.1000\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3521 - accuracy: 0.1000 - val_loss: 2.3512 - val_accuracy: 0.1000\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3506 - accuracy: 0.1000 - val_loss: 2.3498 - val_accuracy: 0.1000\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3491 - accuracy: 0.1000 - val_loss: 2.3486 - val_accuracy: 0.1000\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3477 - accuracy: 0.1000 - val_loss: 2.3473 - val_accuracy: 0.1000\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3464 - accuracy: 0.1000 - val_loss: 2.3461 - val_accuracy: 0.1000\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3450 - accuracy: 0.1000 - val_loss: 2.3450 - val_accuracy: 0.1000\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3437 - accuracy: 0.1000 - val_loss: 2.3438 - val_accuracy: 0.1000\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3425 - accuracy: 0.1000 - val_loss: 2.3427 - val_accuracy: 0.1000\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3413 - accuracy: 0.1000 - val_loss: 2.3416 - val_accuracy: 0.1000\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3401 - accuracy: 0.1000 - val_loss: 2.3406 - val_accuracy: 0.1000\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 2.3389 - accuracy: 0.1000 - val_loss: 2.3396 - val_accuracy: 0.1000\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 2.3377 - accuracy: 0.1000 - val_loss: 2.3386 - val_accuracy: 0.1000\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3366 - accuracy: 0.1000 - val_loss: 2.3376 - val_accuracy: 0.1000\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3355 - accuracy: 0.1000 - val_loss: 2.3366 - val_accuracy: 0.1000\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3345 - accuracy: 0.1000 - val_loss: 2.3357 - val_accuracy: 0.1000\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3335 - accuracy: 0.1000 - val_loss: 2.3348 - val_accuracy: 0.1000\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3324 - accuracy: 0.1000 - val_loss: 2.3339 - val_accuracy: 0.1000\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3315 - accuracy: 0.1000 - val_loss: 2.3331 - val_accuracy: 0.1000\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3305 - accuracy: 0.1000 - val_loss: 2.3322 - val_accuracy: 0.1000\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3295 - accuracy: 0.1000 - val_loss: 2.3314 - val_accuracy: 0.1000\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3286 - accuracy: 0.1000 - val_loss: 2.3306 - val_accuracy: 0.1000\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3277 - accuracy: 0.1000 - val_loss: 2.3298 - val_accuracy: 0.1000\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3268 - accuracy: 0.1000 - val_loss: 2.3291 - val_accuracy: 0.1000\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3260 - accuracy: 0.1000 - val_loss: 2.3283 - val_accuracy: 0.1000\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3251 - accuracy: 0.1000 - val_loss: 2.3276 - val_accuracy: 0.1000\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3243 - accuracy: 0.1000 - val_loss: 2.3269 - val_accuracy: 0.1000\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3235 - accuracy: 0.1000 - val_loss: 2.3262 - val_accuracy: 0.1000\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 2.3227 - accuracy: 0.1000 - val_loss: 2.3255 - val_accuracy: 0.1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5589353390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr2YsZV0OIV0",
        "colab_type": "text"
      },
      "source": [
        "## Review model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4ojW6-oOIV2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "81eef3be-744d-4a5d-d880-f6ee830fd18b"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels_OH, verbose=2)\n",
        "\n",
        "print('Test accuracy:-', test_acc)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/1 - 0s - loss: 1.6564 - accuracy: 0.5336\n",
            "('Test accuracy:-', 0.5336)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6xiJosOnCJY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "e143db36-84da-4791-dc81-0902645c634e"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_11 (Reshape)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "Layer_1 (Dense)              (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "Layer_2 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "Layer_3 (Dense)              (None, 10)                1010      \n",
            "_________________________________________________________________\n",
            "Output (Dense)               (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 92,856\n",
            "Trainable params: 91,288\n",
            "Non-trainable params: 1,568\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}