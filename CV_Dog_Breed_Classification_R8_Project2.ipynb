{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_Dog_Breed_Classification_R8_Project2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2kIWaR5ZpKlJ"
      },
      "source": [
        "## Dog Breed Classification\n",
        "\n",
        "In this project we will use traditional CNN, CNN with data augmentation and finally transfer Learning by VGG16 model with weights pre-trained on Imagenet to solve the dog breed classification problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F7MDmaAw2xGO"
      },
      "source": [
        "### Load Dataset Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BZWpQv1OwqYK",
        "colab": {}
      },
      "source": [
        "#Import necessary libraries to fetch the train and test data...\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlQkULc7wJPj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b8e91f6a-5f96-407f-b51c-4741e9b75235"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "tf.random.set_seed(42)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhCH8Mib1LxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fVhB9OopxFbX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "fda3660a-da26-42e1-b538-43b3926461a0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1q2zzIaUprk_"
      },
      "source": [
        "Now, upload the given dataset file shared with you in your google drive and give its path for the below given `project_path` variable. For example, a path is given below according to the file path in our google drive. You need to change this to match the path of yours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tp6FvAToxUFs",
        "colab": {}
      },
      "source": [
        "project_path = \"/content/drive/My Drive/Great_Lakes_Assignments/10_ComputerVision_CNN_Project2/DogBreed_Classification/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rydR_j8lqUei"
      },
      "source": [
        "Run the below code to extract all the images in the train.zip files given in the dataset. We are going to use these images as train and validation sets and their labels in further steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3350WZM4w4EL",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(project_path+'train.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NHq1iBCfFjE",
        "colab_type": "text"
      },
      "source": [
        "Repeat the same step for test.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_fxzynvB2YCb",
        "colab": {}
      },
      "source": [
        "with ZipFile(project_path+'test.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnUMhQrDfJmz",
        "colab_type": "text"
      },
      "source": [
        "Repeat the same step for sample_submission.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4PyTxE8q2jLf",
        "colab": {}
      },
      "source": [
        "with ZipFile(project_path+'sample_submission.csv.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G9RIxB-fOLT",
        "colab_type": "text"
      },
      "source": [
        "Repeat the same step for labels.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rXtnEoEixbgi",
        "colab": {}
      },
      "source": [
        "with ZipFile(project_path+'labels.csv.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJc1lVrW_jmL",
        "colab_type": "text"
      },
      "source": [
        "After this process, we will have 4 files - Train folder, test folder and labels.csv and sample_submission.csv as part of your google drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aYmJKmDqqpng"
      },
      "source": [
        "### Read labels.csv file using pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmlJ2VMY96IZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_labels = pd.read_csv('/content/labels.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPvb1RSc96If",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "30706b45-c99e-438f-abc6-2822bd5107c6"
      },
      "source": [
        "df_labels.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>breed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
              "      <td>boston_bull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
              "      <td>dingo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
              "      <td>pekinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
              "      <td>bluetick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
              "      <td>golden_retriever</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 id             breed\n",
              "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
              "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
              "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
              "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
              "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QP8YAzQvqyK-"
      },
      "source": [
        "### Print the count of each category of Dogs given in the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L2naXlr96Im",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "72f205db-505c-440f-c53a-02473db63657"
      },
      "source": [
        "print('Total count of dogs: ', df_labels.shape[0])\n",
        "print('Number of dog Category: ', len(df_labels.breed.unique()))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total count of dogs:  10222\n",
            "Number of dog Category:  120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLm3W5RN96Ir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "e3bb75d9-a629-4dfc-9f1b-64c511cad4f6"
      },
      "source": [
        "print('Count of each category of Dogs:')\n",
        "df_labels.groupby('breed').size()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of each category of Dogs:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "breed\n",
              "affenpinscher                      80\n",
              "afghan_hound                      116\n",
              "african_hunting_dog                86\n",
              "airedale                          107\n",
              "american_staffordshire_terrier     74\n",
              "                                 ... \n",
              "welsh_springer_spaniel             79\n",
              "west_highland_white_terrier        81\n",
              "whippet                            95\n",
              "wire-haired_fox_terrier            82\n",
              "yorkshire_terrier                  82\n",
              "Length: 120, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WI94_Qcc0D4M"
      },
      "source": [
        "### Get one-hot encodings of labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q48iAcY196I3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get lable encoding for labels\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(df_labels.breed)\n",
        "df_labels['breedEncoded'] = le.transform(df_labels.breed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nlWmRNM96I8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "c919c156-77b1-4e76-a94c-1e1524b8c5f2"
      },
      "source": [
        "df_labels.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>breed</th>\n",
              "      <th>breedEncoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
              "      <td>boston_bull</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
              "      <td>dingo</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
              "      <td>pekinese</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
              "      <td>bluetick</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
              "      <td>golden_retriever</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 id             breed  breedEncoded\n",
              "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull            19\n",
              "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo            37\n",
              "2  001cdf01b096e06d78e9e5112d419397          pekinese            85\n",
              "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick            15\n",
              "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever            49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwV0sXs1wRyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = tf.keras.utils.to_categorical(df_labels.breedEncoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQNhPw8VwXzf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "0fd1eceb-30b1-484b-92e4-c73783cfa0d9"
      },
      "source": [
        "labels"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmr8mj6-wf72",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4b964602-e571-4a6c-ecd5-e25c14b77ac9"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10222, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWaJ9naXfoiU",
        "colab_type": "text"
      },
      "source": [
        "## Preparing training dataset\n",
        "1. Write a code which reads each and every id from labels.csv file and loads the corresponding image (in RGB - 128, 128, 3) from the train folder. <br>\n",
        "2. Create 2 variables <br> \n",
        "     a.  x_train - Should have all the images of the dogs from train folder <br>\n",
        "     b.  y_train - Corresponding label of the dog <br>\n",
        "<u>Note:</u> The id of the dog images and its corresponding labels are available in labels.csv file   \n",
        "<u>Hint:</u> Watch the video shared on \"Preparing the training dataset\" if you face issue on creating the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aC2f9ecR0XGR",
        "colab": {}
      },
      "source": [
        "X_train = []\n",
        "\n",
        "ImgCnt = df_labels.shape[0]\n",
        "\n",
        "for i in range(ImgCnt):\n",
        "  try:\n",
        "      dummy = cv2.imread('/content/train/' + df_labels.id[i] + '.jpg')\n",
        "      dummy = cv2.resize(dummy,(128,128)) #resize to have all the images of same size\n",
        "      X_train.append(dummy)\n",
        "  except Exception as e:\n",
        "      print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nkkZEpOe0ipk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5b9fd6db-d1ba-4640-bd53-5d0bd67266f8"
      },
      "source": [
        "print('x_train Count: ', len(X_train))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train Count:  10222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ioWDEgElBOs",
        "colab_type": "text"
      },
      "source": [
        "Normalize the training data and convert into 4 dimensions so that it can be used as an input to conv layers in the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ARn76j3U1CDa",
        "colab": {}
      },
      "source": [
        "#Convert the list to numpy array for easy manipulation...\n",
        "X_train_arr = np.asarray(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj2f5-EJxhce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_std = X_train_arr/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDJOP0-0xqpG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6860edfa-81e4-47ad-fff8-528bc16aa9ef"
      },
      "source": [
        "X_train_std.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10222, 128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZwQ--Scxhoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_std = X_train_std.reshape(X_train_std.shape[0], 128, 128, 3).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldDMKGg3xtej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8d97f206-fdf0-498b-f3af-e982bbd5e500"
      },
      "source": [
        "X_train_std.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10222, 128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bdCXuAE11gZL"
      },
      "source": [
        "### Split the training and validation data from `x_train_data` and `y_train_data` obtained from above step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpWx-pgV96Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_std, labels, test_size=0.2, random_state=2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_uYHBByzTbV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "71e04d42-f05c-47e5-a91b-f5fc534b76f5"
      },
      "source": [
        "print (\"No. of images in train dataset: \", len(X_train_split))\n",
        "print (\"No. of images in Validation dataset: \", len(X_val_split))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of images in train dataset:  8177\n",
            "No. of images in Validation dataset:  2045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XkL-N1jDsU8m"
      },
      "source": [
        "### Loading the test data\n",
        "Read the id column from the samples_submission.csv and store it in test_img"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DnpXdpd9b3E7",
        "colab": {}
      },
      "source": [
        "test_img = pd.read_csv('/content/sample_submission.csv')['id']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHOUcCWbzhJZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "d32d4715-2f16-4c90-f5db-3478e3c77fbc"
      },
      "source": [
        "test_img.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    000621fb3cbb32d8935728e48679680e\n",
              "1    00102ee9d8eb90812350685311fe5890\n",
              "2    0012a730dfa437f5f3613fb75efcd4ce\n",
              "3    001510bc8570bbeee98c8d80c8a95ec1\n",
              "4    001a5f3114548acdefa3d4da05474c2e\n",
              "Name: id, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUO5lo4Izj4Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "dc36f465-c390-4601-e312-a2e9f0a2dd2f"
      },
      "source": [
        "test_img.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10357,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEJqZIMbm0Jo",
        "colab_type": "text"
      },
      "source": [
        "Run the below code to load the test image files in x_test_feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow5Cw1buz0lc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_feature = []\n",
        "ImgCnt = len(test_img)\n",
        "\n",
        "for i in range(ImgCnt):\n",
        "  try:\n",
        "      dummy = cv2.imread('/content/test/' + test_img[i] + '.jpg')\n",
        "      dummy = cv2.resize(dummy,(128,128)) #resize to have all the images of same size\n",
        "      x_test_feature.append(dummy)\n",
        "  except Exception as e:\n",
        "      print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbozAsFr0S3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "604ac1f9-737f-4c35-d182-1e87d58d46df"
      },
      "source": [
        "print('x_test_feature Count: ', len(x_test_feature))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test_feature Count:  10357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9My6qSyDnE-_",
        "colab_type": "text"
      },
      "source": [
        "Normalize the test data and convert it into 4 dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzGjyMPa0eeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert the list to numpy array for easy manipulation...\n",
        "X_test_arr = np.asarray(x_test_feature)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCKjJcPa0gDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_std = X_test_arr/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "769Zx2os0k8q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ab4dad73-bfad-41e3-d2f4-943a969fa060"
      },
      "source": [
        "X_test_std.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10357, 128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhVWmSnF0nv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_std = X_test_std.reshape(X_test_std.shape[0], 128, 128, 3).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Eldit6p0n9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "017d75e1-e2c8-4bf5-e9b0-20af4874217a"
      },
      "source": [
        "X_test_std.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10357, 128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zKezNJVMsocP"
      },
      "source": [
        "### Build a basic conv neural network with 2 conv layers (kernel sizes - 5 and 3) add layers as mentioned below for classification.\n",
        "\n",
        "1. Add a Dense layer with 256 neurons with `relu` activation\n",
        "\n",
        "2. Add a Dense layer with 120 neurons as final layer (as there are 120 classes in the given dataset) with `softmax` activation for classifiaction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2jxTY2S96J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, input_shape = (128,128,3), kernel_size=5)) \n",
        "model.add(Conv2D(filters=64, kernel_size=3))\n",
        "\n",
        "model.add(Flatten()) \n",
        "\n",
        "# fully connected layer\n",
        "model.add(Dense(units=256, kernel_initializer = 'he_normal', activation = 'relu'))\n",
        "model.add(Dense(units = 120, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_BAvCzo96J6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okoj-E2S4EiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving the best model using model checkpoint callback\n",
        "model1_checkpoint=tf.keras.callbacks.ModelCheckpoint('model1.h5',save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui8EXw6_oqpR",
        "colab_type": "text"
      },
      "source": [
        "### Use batch_size = 128 and epochs = 10 and execute the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmVH_lZh3qfX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "465c2f18-cca2-4037-b68d-3b9c81f6f78d"
      },
      "source": [
        "Model_1 = model.fit(X_train_split, y_train_split,\n",
        "                    epochs=10, \n",
        "                    validation_data=(X_val_split, y_val_split),\n",
        "                    verbose = 1,\n",
        "                    batch_size=128, callbacks = [model1_checkpoint])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8177 samples, validate on 2045 samples\n",
            "Epoch 1/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 13.2790 - accuracy: 0.0098\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.01027, saving model to model1.h5\n",
            "8177/8177 [==============================] - 115s 14ms/sample - loss: 13.1617 - accuracy: 0.0098 - val_loss: 4.7878 - val_accuracy: 0.0103\n",
            "Epoch 2/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 4.7860 - accuracy: 0.0089\n",
            "Epoch 00002: val_accuracy did not improve from 0.01027\n",
            "8177/8177 [==============================] - 92s 11ms/sample - loss: 4.7864 - accuracy: 0.0089 - val_loss: 4.7888 - val_accuracy: 0.0103\n",
            "Epoch 3/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 4.7831 - accuracy: 0.0124\n",
            "Epoch 00003: val_accuracy did not improve from 0.01027\n",
            "8177/8177 [==============================] - 94s 12ms/sample - loss: 4.7832 - accuracy: 0.0124 - val_loss: 4.7865 - val_accuracy: 0.0103\n",
            "Epoch 4/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 4.7807 - accuracy: 0.0118\n",
            "Epoch 00004: val_accuracy did not improve from 0.01027\n",
            "8177/8177 [==============================] - 90s 11ms/sample - loss: 4.7806 - accuracy: 0.0119 - val_loss: 4.7862 - val_accuracy: 0.0103\n",
            "Epoch 5/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 4.7776 - accuracy: 0.0122\n",
            "Epoch 00005: val_accuracy did not improve from 0.01027\n",
            "8177/8177 [==============================] - 89s 11ms/sample - loss: 4.7776 - accuracy: 0.0121 - val_loss: 4.7862 - val_accuracy: 0.0083\n",
            "Epoch 6/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 4.7757 - accuracy: 0.0136\n",
            "Epoch 00006: val_accuracy did not improve from 0.01027\n",
            "8177/8177 [==============================] - 89s 11ms/sample - loss: 4.7757 - accuracy: 0.0135 - val_loss: 4.7889 - val_accuracy: 0.0078\n",
            "Epoch 7/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 4.7733 - accuracy: 0.0120\n",
            "Epoch 00007: val_accuracy did not improve from 0.01027\n",
            "8177/8177 [==============================] - 89s 11ms/sample - loss: 4.7734 - accuracy: 0.0120 - val_loss: 4.7961 - val_accuracy: 0.0078\n",
            "Epoch 8/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 4.7708 - accuracy: 0.0134\n",
            "Epoch 00008: val_accuracy did not improve from 0.01027\n",
            "8177/8177 [==============================] - 91s 11ms/sample - loss: 4.7708 - accuracy: 0.0136 - val_loss: 4.7875 - val_accuracy: 0.0078\n",
            "Epoch 9/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 4.7718 - accuracy: 0.0133\n",
            "Epoch 00009: val_accuracy did not improve from 0.01027\n",
            "8177/8177 [==============================] - 90s 11ms/sample - loss: 4.7719 - accuracy: 0.0132 - val_loss: 4.7862 - val_accuracy: 0.0078\n",
            "Epoch 10/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 4.7837 - accuracy: 0.0141\n",
            "Epoch 00010: val_accuracy did not improve from 0.01027\n",
            "8177/8177 [==============================] - 90s 11ms/sample - loss: 4.7840 - accuracy: 0.0141 - val_loss: 4.8068 - val_accuracy: 0.0083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8hWaKmjoz69",
        "colab_type": "text"
      },
      "source": [
        "#The model accuracy is very poor !!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "agJKkc6xtKiq"
      },
      "source": [
        "### Use Data Augmentation in the above model to see if the accuracy improves\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "31Mn8qnZb3Ru",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "32af3388-1a72-47fa-c79d-bce7a9db2e4c"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDLQVFDP96KI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator( rotation_range=90,\n",
        "                 width_shift_range=0.1, height_shift_range=0.1,\n",
        "                 horizontal_flip=True)\n",
        "train_datagen.fit(X_train_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bqTlW0qHb3Xb",
        "colab": {}
      },
      "source": [
        "val_datagen = ImageDataGenerator( rotation_range=90,\n",
        "                 width_shift_range=0.1, height_shift_range=0.1,\n",
        "                 horizontal_flip=True)\n",
        "val_datagen.fit(X_val_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6sssbaTfxlkk"
      },
      "source": [
        "### Using the above objects, create the image generators with variable names `train_generator` and `val_generator`\n",
        "\n",
        "You need to use train_datagen.flow() and val_datagen.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sehaRgT-96KQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = train_datagen.flow(X_train_split, y_train_split, batch_size=10)\n",
        "val_generator = val_datagen.flow(X_val_split, y_val_split, batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TVFQJZw3x4-C"
      },
      "source": [
        "### Fit the model using fit_generator() using `train_generator` and `val_generator` from the above step with 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J1K2MqHbuPUa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "578d3b7b-db7d-44b4-acbe-62163060e01b"
      },
      "source": [
        "model.fit_generator(train_generator,\\\n",
        "                    epochs=10, steps_per_epoch= X_train_split.shape[0]//32, \\\n",
        "                    verbose=1,validation_data=val_generator, validation_steps = X_val_split.shape[0]//32)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 255 steps, validate for 63 steps\n",
            "Epoch 1/10\n",
            "255/255 [==============================] - 93s 366ms/step - loss: 4.7752 - accuracy: 0.0114 - val_loss: 4.7888 - val_accuracy: 0.0111\n",
            "Epoch 2/10\n",
            "255/255 [==============================] - 93s 365ms/step - loss: 4.7742 - accuracy: 0.0090 - val_loss: 4.7893 - val_accuracy: 0.0111\n",
            "Epoch 3/10\n",
            "255/255 [==============================] - 93s 366ms/step - loss: 4.7755 - accuracy: 0.0094 - val_loss: 4.7899 - val_accuracy: 0.0111\n",
            "Epoch 4/10\n",
            "255/255 [==============================] - 91s 359ms/step - loss: 4.7751 - accuracy: 0.0125 - val_loss: 4.7902 - val_accuracy: 0.0159\n",
            "Epoch 5/10\n",
            "255/255 [==============================] - 93s 365ms/step - loss: 4.7772 - accuracy: 0.0102 - val_loss: 4.7902 - val_accuracy: 0.0159\n",
            "Epoch 6/10\n",
            "255/255 [==============================] - 94s 367ms/step - loss: 4.7771 - accuracy: 0.0149 - val_loss: 4.7896 - val_accuracy: 0.0159\n",
            "Epoch 7/10\n",
            "255/255 [==============================] - 95s 374ms/step - loss: 4.7774 - accuracy: 0.0145 - val_loss: 4.7898 - val_accuracy: 0.0159\n",
            "Epoch 8/10\n",
            "255/255 [==============================] - 93s 363ms/step - loss: 4.7742 - accuracy: 0.0133 - val_loss: 4.7896 - val_accuracy: 0.0159\n",
            "Epoch 9/10\n",
            "255/255 [==============================] - 93s 364ms/step - loss: 4.7772 - accuracy: 0.0106 - val_loss: 4.7905 - val_accuracy: 0.0159\n",
            "Epoch 10/10\n",
            "255/255 [==============================] - 92s 362ms/step - loss: 4.7741 - accuracy: 0.0110 - val_loss: 4.7909 - val_accuracy: 0.0159\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd171da99b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2zmLztqo5DY",
        "colab_type": "text"
      },
      "source": [
        "# Model accuracy is still poor!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSTATrhsAo7L",
        "colab_type": "text"
      },
      "source": [
        "### Lets use Transfer Learning\n",
        "\n",
        "Download the vgg wieght file from here : https://github.com/MinerKasch/applied_deep_learning/blob/master/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA4Umsgv8iUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "project_path = \"/content/drive/My Drive/Great_Lakes_Assignments/10_ComputerVision_CNN_Project2/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy5JdbW6pIvD",
        "colab_type": "text"
      },
      "source": [
        "Use the below code to load VGG16 weights trained on ImageNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK_2F48-L7-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define some parameters\n",
        "img_size = 128\n",
        "img_depth = 3  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrqs0zg7ApNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "# Instantiate the model with the pre-trained weights (no top)\n",
        "base_model= VGG16(include_top=False, input_shape=(img_size,img_size, img_depth)\n",
        "                 , pooling='avg',weights=project_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EItOlRBGpV_A",
        "colab_type": "text"
      },
      "source": [
        "Print the summary of the base_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQsEBgnlpHjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "outputId": "977844e9-c174-4ede-bf24-acc320960616"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcpxHDvFO9SK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "7e74dd65-26fa-4b88-a106-9782806a7a8a"
      },
      "source": [
        "base_model.output"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'global_average_pooling2d_1/Identity:0' shape=(None, 512) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeQem0pHITIj",
        "colab_type": "text"
      },
      "source": [
        "### Make all the layers in the base_model (VGG16) to be non-trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbSGveqPPO1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Set pre-trained model layers to not trainable\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHpeOyW0qauW",
        "colab_type": "text"
      },
      "source": [
        "### Add the following classification layers to the imported VGG Model <br>\n",
        "1. Flatten Layer\n",
        "2. Dense layer with 1024 neurons with activation as Relu\n",
        "3. Dense layer with 256 neurons with activation as Relu\n",
        "4. Dense layer with 120 neurons with activation as Softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwZvF_EtPa6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get Output layer of Pre0trained model\n",
        "x = base_model.output\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(units=1024, activation = 'relu')(x)\n",
        "x = Dense(units=256, activation = 'relu')(x)\n",
        "#Add output layer\n",
        "prediction = Dense(units = 120, activation = 'softmax')(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZspQVf_QBY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using Keras Model class\n",
        "final_model = tf.keras.models.Model(inputs=base_model.input, #Pre-trained model input as input layer\n",
        "                                    outputs=prediction) #Output layer added"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKrftzZaQvBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VpHw_wGQxd3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "outputId": "cf9b516c-647c-4176-ae71-8ca15e615a03"
      },
      "source": [
        "final_model.summary()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 120)               30840     \n",
            "=================================================================\n",
            "Total params: 15,533,240\n",
            "Trainable params: 818,552\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srNQMEUBRKFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batchsize=128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj-BwqgfIkdv",
        "colab_type": "text"
      },
      "source": [
        "### Fit and compile the model with batch_size = 128 and epochs = 10 and execute the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD5fAgVQIpKZ",
        "colab_type": "text"
      },
      "source": [
        "Try to get training and validation accuracy to be more than 90%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghr0IIXiTYfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelfinal_checkpoint = tf.keras.callbacks.ModelCheckpoint('modelfinal.h5',save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2zM4AmJ_BYY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "b34b17d0-d356-4504-859b-436a588b973d"
      },
      "source": [
        "Model_Final = final_model.fit(X_train_split, y_train_split,\n",
        "                    epochs=10, \n",
        "                    validation_data=(X_val_split, y_val_split),\n",
        "                    verbose = 1,\n",
        "                    batch_size=128,callbacks = [modelfinal_checkpoint])"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8177 samples, validate on 2045 samples\n",
            "Epoch 1/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 3.7423 - accuracy: 0.1210\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.12078, saving model to modelfinal.h5\n",
            "8177/8177 [==============================] - 105s 13ms/sample - loss: 3.7411 - accuracy: 0.1216 - val_loss: 3.8008 - val_accuracy: 0.1208\n",
            "Epoch 2/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 3.5770 - accuracy: 0.1500\n",
            "Epoch 00002: val_accuracy improved from 0.12078 to 0.12861, saving model to modelfinal.h5\n",
            "8177/8177 [==============================] - 103s 13ms/sample - loss: 3.5738 - accuracy: 0.1504 - val_loss: 3.7062 - val_accuracy: 0.1286\n",
            "Epoch 3/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 3.4604 - accuracy: 0.1670\n",
            "Epoch 00003: val_accuracy improved from 0.12861 to 0.13888, saving model to modelfinal.h5\n",
            "8177/8177 [==============================] - 104s 13ms/sample - loss: 3.4611 - accuracy: 0.1674 - val_loss: 3.6131 - val_accuracy: 0.1389\n",
            "Epoch 4/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 3.3565 - accuracy: 0.1854\n",
            "Epoch 00004: val_accuracy improved from 0.13888 to 0.15844, saving model to modelfinal.h5\n",
            "8177/8177 [==============================] - 103s 13ms/sample - loss: 3.3558 - accuracy: 0.1848 - val_loss: 3.5284 - val_accuracy: 0.1584\n",
            "Epoch 5/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 3.2646 - accuracy: 0.1994\n",
            "Epoch 00005: val_accuracy improved from 0.15844 to 0.16577, saving model to modelfinal.h5\n",
            "8177/8177 [==============================] - 99s 12ms/sample - loss: 3.2628 - accuracy: 0.1993 - val_loss: 3.4953 - val_accuracy: 0.1658\n",
            "Epoch 6/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 3.1791 - accuracy: 0.2111\n",
            "Epoch 00006: val_accuracy improved from 0.16577 to 0.16870, saving model to modelfinal.h5\n",
            "8177/8177 [==============================] - 101s 12ms/sample - loss: 3.1820 - accuracy: 0.2107 - val_loss: 3.4313 - val_accuracy: 0.1687\n",
            "Epoch 7/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 3.1029 - accuracy: 0.2300\n",
            "Epoch 00007: val_accuracy did not improve from 0.16870\n",
            "8177/8177 [==============================] - 100s 12ms/sample - loss: 3.1010 - accuracy: 0.2303 - val_loss: 3.4166 - val_accuracy: 0.1609\n",
            "Epoch 8/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 3.0226 - accuracy: 0.2440\n",
            "Epoch 00008: val_accuracy improved from 0.16870 to 0.17897, saving model to modelfinal.h5\n",
            "8177/8177 [==============================] - 100s 12ms/sample - loss: 3.0224 - accuracy: 0.2439 - val_loss: 3.3558 - val_accuracy: 0.1790\n",
            "Epoch 9/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 2.9478 - accuracy: 0.2653\n",
            "Epoch 00009: val_accuracy improved from 0.17897 to 0.19218, saving model to modelfinal.h5\n",
            "8177/8177 [==============================] - 101s 12ms/sample - loss: 2.9489 - accuracy: 0.2646 - val_loss: 3.3153 - val_accuracy: 0.1922\n",
            "Epoch 10/10\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 2.8798 - accuracy: 0.2742\n",
            "Epoch 00010: val_accuracy improved from 0.19218 to 0.19413, saving model to modelfinal.h5\n",
            "8177/8177 [==============================] - 100s 12ms/sample - loss: 2.8809 - accuracy: 0.2742 - val_loss: 3.2878 - val_accuracy: 0.1941\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qCRwwqzX14N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "ff268310-33e1-4ab4-c44b-84ae3cbcb573"
      },
      "source": [
        "##As we can see the model accurracy is increasing so we can run it for more epochs\n",
        "Model_Final = final_model.fit(X_train_split, y_train_split,\n",
        "                    epochs=20, \n",
        "                    validation_data=(X_val_split, y_val_split),\n",
        "                    verbose = 1,\n",
        "                    batch_size=128,callbacks = [modelfinal_checkpoint],initial_epoch=10)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8177 samples, validate on 2045 samples\n",
            "Epoch 11/20\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 2.8175 - accuracy: 0.2899\n",
            "Epoch 00011: val_accuracy improved from 0.19413 to 0.19902, saving model to modelfinal.h5\n",
            "8177/8177 [==============================] - 102s 13ms/sample - loss: 2.8187 - accuracy: 0.2900 - val_loss: 3.2832 - val_accuracy: 0.1990\n",
            "Epoch 12/20\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 2.7616 - accuracy: 0.3011\n",
            "Epoch 00012: val_accuracy improved from 0.19902 to 0.20831, saving model to modelfinal.h5\n",
            "8177/8177 [==============================] - 100s 12ms/sample - loss: 2.7567 - accuracy: 0.3007 - val_loss: 3.2345 - val_accuracy: 0.2083\n",
            "Epoch 13/20\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 2.6962 - accuracy: 0.3155\n",
            "Epoch 00013: val_accuracy improved from 0.20831 to 0.20978, saving model to modelfinal.h5\n",
            "8177/8177 [==============================] - 101s 12ms/sample - loss: 2.6977 - accuracy: 0.3153 - val_loss: 3.2178 - val_accuracy: 0.2098\n",
            "Epoch 14/20\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 2.6456 - accuracy: 0.3239\n",
            "Epoch 00014: val_accuracy did not improve from 0.20978\n",
            "8177/8177 [==============================] - 100s 12ms/sample - loss: 2.6447 - accuracy: 0.3238 - val_loss: 3.2102 - val_accuracy: 0.2098\n",
            "Epoch 15/20\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 2.5824 - accuracy: 0.3385\n",
            "Epoch 00015: val_accuracy improved from 0.20978 to 0.21858, saving model to modelfinal.h5\n",
            "8177/8177 [==============================] - 100s 12ms/sample - loss: 2.5789 - accuracy: 0.3391 - val_loss: 3.2126 - val_accuracy: 0.2186\n",
            "Epoch 16/20\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 2.5301 - accuracy: 0.3504\n",
            "Epoch 00016: val_accuracy did not improve from 0.21858\n",
            "8177/8177 [==============================] - 100s 12ms/sample - loss: 2.5334 - accuracy: 0.3489 - val_loss: 3.1795 - val_accuracy: 0.2156\n",
            "Epoch 17/20\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 2.4826 - accuracy: 0.3661\n",
            "Epoch 00017: val_accuracy did not improve from 0.21858\n",
            "8177/8177 [==============================] - 107s 13ms/sample - loss: 2.4816 - accuracy: 0.3661 - val_loss: 3.2393 - val_accuracy: 0.2010\n",
            "Epoch 18/20\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 2.4201 - accuracy: 0.3792\n",
            "Epoch 00018: val_accuracy improved from 0.21858 to 0.22103, saving model to modelfinal.h5\n",
            "8177/8177 [==============================] - 100s 12ms/sample - loss: 2.4198 - accuracy: 0.3794 - val_loss: 3.2166 - val_accuracy: 0.2210\n",
            "Epoch 19/20\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 2.3636 - accuracy: 0.3880\n",
            "Epoch 00019: val_accuracy improved from 0.22103 to 0.22152, saving model to modelfinal.h5\n",
            "8177/8177 [==============================] - 100s 12ms/sample - loss: 2.3648 - accuracy: 0.3877 - val_loss: 3.2086 - val_accuracy: 0.2215\n",
            "Epoch 20/20\n",
            "8064/8177 [============================>.] - ETA: 1s - loss: 2.3162 - accuracy: 0.4019\n",
            "Epoch 00020: val_accuracy did not improve from 0.22152\n",
            "8177/8177 [==============================] - 100s 12ms/sample - loss: 2.3176 - accuracy: 0.4014 - val_loss: 3.2021 - val_accuracy: 0.2191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lqKzaaKcHPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = train_datagen.flow(X_train_split, y_train_split, batch_size=128)\n",
        "val_generator = val_datagen.flow(X_val_split, y_val_split, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KobpqQ8Ketv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelfinal1_checkpoint = tf.keras.callbacks.ModelCheckpoint('modelfinal1.h5',save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC9pqZ-NcRPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873
        },
        "outputId": "190fc1e1-b0d3-44ee-887a-b8fc23ab9dc8"
      },
      "source": [
        "final_model.fit_generator(train_generator,\\\n",
        "                    epochs=10, steps_per_epoch=X_train_split.shape[0]//batchsize, \\\n",
        "                    verbose=1,validation_data=val_generator, validation_steps = X_val_split.shape[0]//batchsize,callbacks = [modelfinal1_checkpoint])"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 63 steps, validate for 15 steps\n",
            "Epoch 1/10\n",
            "62/63 [============================>.] - ETA: 1s - loss: 3.2275 - accuracy: 0.2180\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.15469, saving model to modelfinal1.h5\n",
            "63/63 [==============================] - 106s 2s/step - loss: 3.2276 - accuracy: 0.2182 - val_loss: 3.6595 - val_accuracy: 0.1547\n",
            "Epoch 2/10\n",
            "62/63 [============================>.] - ETA: 1s - loss: 3.2086 - accuracy: 0.2264\n",
            "Epoch 00002: val_accuracy did not improve from 0.15469\n",
            "63/63 [==============================] - 106s 2s/step - loss: 3.2099 - accuracy: 0.2272 - val_loss: 3.6300 - val_accuracy: 0.1521\n",
            "Epoch 3/10\n",
            "62/63 [============================>.] - ETA: 1s - loss: 3.1626 - accuracy: 0.2358\n",
            "Epoch 00003: val_accuracy improved from 0.15469 to 0.16563, saving model to modelfinal1.h5\n",
            "63/63 [==============================] - 106s 2s/step - loss: 3.1598 - accuracy: 0.2365 - val_loss: 3.6135 - val_accuracy: 0.1656\n",
            "Epoch 4/10\n",
            "62/63 [============================>.] - ETA: 1s - loss: 3.1424 - accuracy: 0.2424\n",
            "Epoch 00004: val_accuracy improved from 0.16563 to 0.16823, saving model to modelfinal1.h5\n",
            "63/63 [==============================] - 106s 2s/step - loss: 3.1413 - accuracy: 0.2414 - val_loss: 3.6036 - val_accuracy: 0.1682\n",
            "Epoch 5/10\n",
            "62/63 [============================>.] - ETA: 1s - loss: 3.1229 - accuracy: 0.2434\n",
            "Epoch 00005: val_accuracy did not improve from 0.16823\n",
            "63/63 [==============================] - 106s 2s/step - loss: 3.1209 - accuracy: 0.2434 - val_loss: 3.6483 - val_accuracy: 0.1464\n",
            "Epoch 6/10\n",
            "62/63 [============================>.] - ETA: 1s - loss: 3.0885 - accuracy: 0.2510\n",
            "Epoch 00006: val_accuracy did not improve from 0.16823\n",
            "63/63 [==============================] - 106s 2s/step - loss: 3.0897 - accuracy: 0.2502 - val_loss: 3.6176 - val_accuracy: 0.1604\n",
            "Epoch 7/10\n",
            "62/63 [============================>.] - ETA: 1s - loss: 3.0811 - accuracy: 0.2535\n",
            "Epoch 00007: val_accuracy improved from 0.16823 to 0.17188, saving model to modelfinal1.h5\n",
            "63/63 [==============================] - 106s 2s/step - loss: 3.0811 - accuracy: 0.2536 - val_loss: 3.5989 - val_accuracy: 0.1719\n",
            "Epoch 8/10\n",
            "62/63 [============================>.] - ETA: 1s - loss: 3.0513 - accuracy: 0.2603\n",
            "Epoch 00008: val_accuracy improved from 0.17188 to 0.17917, saving model to modelfinal1.h5\n",
            "63/63 [==============================] - 107s 2s/step - loss: 3.0525 - accuracy: 0.2600 - val_loss: 3.5839 - val_accuracy: 0.1792\n",
            "Epoch 9/10\n",
            "62/63 [============================>.] - ETA: 1s - loss: 3.0333 - accuracy: 0.2548\n",
            "Epoch 00009: val_accuracy did not improve from 0.17917\n",
            "63/63 [==============================] - 106s 2s/step - loss: 3.0329 - accuracy: 0.2551 - val_loss: 3.6026 - val_accuracy: 0.1646\n",
            "Epoch 10/10\n",
            "62/63 [============================>.] - ETA: 1s - loss: 3.0072 - accuracy: 0.2596\n",
            "Epoch 00010: val_accuracy did not improve from 0.17917\n",
            "63/63 [==============================] - 106s 2s/step - loss: 3.0090 - accuracy: 0.2594 - val_loss: 3.6069 - val_accuracy: 0.1693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd1733b88d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    }
  ]
}