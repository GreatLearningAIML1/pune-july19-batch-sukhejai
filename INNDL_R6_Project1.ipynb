{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNDL_R6_Project_1_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU7XFuvK7ohE",
        "colab_type": "text"
      },
      "source": [
        "#Neural Network & Deep learning | Project 1\n",
        "\n",
        "This project has 2 case studies.\n",
        "\n",
        "The first case study (described below - 30 points) covers concepts taught in Part 1 (first 8 hours of Neural networks basics).\n",
        " \n",
        "1st case study - Project 1:\n",
        " \n",
        "The case study is from an open source dataset from Kaggle. \n",
        "\n",
        "Link to the Kaggle project site:\n",
        "https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling\n",
        "\n",
        "Given a Bank customer, can we build a classifier which can determine whether they will leave or not using Neural networks?\n",
        "\n",
        "Case file: \n",
        "\n",
        "Dataset - bank.csv\n",
        " \n",
        "The points distribution for this case is as follows:\n",
        "1. Read the dataset in a new python notebook.\n",
        "2. Drop the columns which are unique for all users like IDs (2.5 points)\n",
        "3. Distinguish the feature and target set (2.5 points)\n",
        "4. Divide the data set into Train and test sets\n",
        "5. Normalize the train and test data (2.5 points)\n",
        "6. Initialize &amp; build the model (10 points)\n",
        "7. Optimize the model (5 points)\n",
        "9. Predict the results using 0.5 as a threshold (5 points)\n",
        "10. Print the Accuracy score and confusion matrix (2.5 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pZVApv4-AvF",
        "colab_type": "code",
        "outputId": "b4bc2cad-ddef-4eba-a664-548674726c77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOMbgyZ6Mc9c",
        "colab_type": "code",
        "outputId": "5ba4c904-2403-4608-a492-d7233fa5fa92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/9a/6a3985daf15d0b87b1ef3c499293cf0889cd294223a6ca28b9529770b29e/tensorflow_gpu-2.0.0-cp27-cp27mu-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 33kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.2.2 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu) (1.16.4)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu) (2.0.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/3d/993131c622ae34f9401a81526853f2310a4834bd042420a7982fb5bc5fd0/tensorboard-2.0.2-py2-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 32.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu) (3.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: backports.weakref>=1.0rc1; python_version < \"3.4\" in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu) (1.0.post1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu) (0.33.6)\n",
            "Requirement already satisfied: functools32>=3.2.3 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu) (3.2.3.post2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu) (0.7.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu) (2.3.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu) (0.1.7)\n",
            "Requirement already satisfied: enum34>=1.1.6; python_version < \"3.4\" in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu) (1.1.6)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 66.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu) (0.8.0)\n",
            "Requirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow-gpu) (3.2.0)\n",
            "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow-gpu) (1.0.2)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow-gpu) (5.4.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (42.0.2)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python2.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.15.5)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/f8/84b5771faec3eba9fe0c91c8c5896364a8ba08852c0dea5ad2025026dd95/google_auth-1.10.0-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python2.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python2.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.2.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.2.5)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (4.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /usr/local/lib/python2.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.5)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-auth, google-auth-oauthlib, tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: google-auth-oauthlib 0.4.0\n",
            "    Uninstalling google-auth-oauthlib-0.4.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-0.4.0\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.0\n",
            "    Uninstalling tensorflow-estimator-1.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.0\n",
            "Successfully installed google-auth-1.10.0 google-auth-oauthlib-0.4.1 tensorboard-2.0.2 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_M6lChzMhXR",
        "colab_type": "code",
        "outputId": "449b9d29-c18b-465f-c10c-d3ec15268c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#%tensorflow_version 2.x\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "tf.random.set_seed(42)\n",
        "print(tf.__version__)\n",
        "#From tensorflow v2.0 onwards, Eager Execution will be enabled by default"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqcqr2zm9MIt",
        "colab_type": "text"
      },
      "source": [
        "##1. Read the dataset in a new python notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUs4jo2j9Hk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKEpSlkq_3R6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bank_data = pd.read_csv('/content/drive/My Drive/Great_Lakes_Assignments/08_Neural_Network_Deep_Learning_R6_Project1/bank.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psOJB4gvA6kY",
        "colab_type": "code",
        "outputId": "5230d875-3e38-4a5d-ef34-3a4849e83be0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "bank_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V0mQCTJAPas",
        "colab_type": "code",
        "outputId": "66df9a51-6498-4ef2-9f5c-d296d81d5161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bank_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHu833n4AYUu",
        "colab_type": "code",
        "outputId": "a34fc8ad-9ba1-491a-fb42-c5ee604d6b84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "bank_data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            "RowNumber          10000 non-null int64\n",
            "CustomerId         10000 non-null int64\n",
            "Surname            10000 non-null object\n",
            "CreditScore        10000 non-null int64\n",
            "Geography          10000 non-null object\n",
            "Gender             10000 non-null object\n",
            "Age                10000 non-null int64\n",
            "Tenure             10000 non-null int64\n",
            "Balance            10000 non-null float64\n",
            "NumOfProducts      10000 non-null int64\n",
            "HasCrCard          10000 non-null int64\n",
            "IsActiveMember     10000 non-null int64\n",
            "EstimatedSalary    10000 non-null float64\n",
            "Exited             10000 non-null int64\n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEwpm08vB-JF",
        "colab_type": "text"
      },
      "source": [
        "###Insights\n",
        "- We have 10000 rows and 14 features.\n",
        "- Some of the features like Rownumber, CustomerId, Surname will not be useful for evaluation as they are unique for all users which does not describe any characteristics for our predictions. These features can be dropped.\n",
        "- There are some features with object type. These features should be converted to category or Label encoding should be done before evaluation.\n",
        "- The target feature Exited is of binary type (0 or 1)\n",
        "- All the features have varied scale of measurement. Noramlization should be done before evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTy38vCt9Ppp",
        "colab_type": "text"
      },
      "source": [
        "##2. Drop the columns which are unique for all users like IDs (2.5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3FmAAKvBNBx",
        "colab_type": "code",
        "outputId": "61a91ec3-b91f-4fed-ae3c-71b6d3cd08e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "# Getting idea of unique values in our dataset \n",
        "for i  in bank_data.columns:\n",
        "    print'Unique vlaues present in {} are : '.format(i),(bank_data[i].nunique())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique vlaues present in RowNumber are :  10000\n",
            "Unique vlaues present in CustomerId are :  10000\n",
            "Unique vlaues present in Surname are :  2932\n",
            "Unique vlaues present in CreditScore are :  460\n",
            "Unique vlaues present in Geography are :  3\n",
            "Unique vlaues present in Gender are :  2\n",
            "Unique vlaues present in Age are :  70\n",
            "Unique vlaues present in Tenure are :  11\n",
            "Unique vlaues present in Balance are :  6382\n",
            "Unique vlaues present in NumOfProducts are :  4\n",
            "Unique vlaues present in HasCrCard are :  2\n",
            "Unique vlaues present in IsActiveMember are :  2\n",
            "Unique vlaues present in EstimatedSalary are :  9999\n",
            "Unique vlaues present in Exited are :  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Dkwk9ra9aVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bank_data.drop(['RowNumber', 'CustomerId', 'Surname'], axis = 1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCaSESlc9aQe",
        "colab_type": "code",
        "outputId": "7267171b-5ab8-4167-ab9a-340386c3ee99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bank_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-VI2oT2DB9E",
        "colab_type": "code",
        "outputId": "f6f996bc-492a-4e87-b204-ec59b6afdaa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "bank_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore Geography  Gender  ...  IsActiveMember  EstimatedSalary  Exited\n",
              "0          619    France  Female  ...               1        101348.88       1\n",
              "1          608     Spain  Female  ...               1        112542.58       0\n",
              "2          502    France  Female  ...               0        113931.57       1\n",
              "3          699    France  Female  ...               0         93826.63       0\n",
              "4          850     Spain  Female  ...               1         79084.10       0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV6FDTSyEAzq",
        "colab_type": "code",
        "outputId": "a535ed2e-2730-42d3-e86b-01067b433d38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "bank_data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 11 columns):\n",
            "CreditScore        10000 non-null int64\n",
            "Geography          10000 non-null object\n",
            "Gender             10000 non-null object\n",
            "Age                10000 non-null int64\n",
            "Tenure             10000 non-null int64\n",
            "Balance            10000 non-null float64\n",
            "NumOfProducts      10000 non-null int64\n",
            "HasCrCard          10000 non-null int64\n",
            "IsActiveMember     10000 non-null int64\n",
            "EstimatedSalary    10000 non-null float64\n",
            "Exited             10000 non-null int64\n",
            "dtypes: float64(2), int64(7), object(2)\n",
            "memory usage: 859.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPEQ3WQfEQB-",
        "colab_type": "code",
        "outputId": "088a184f-46d8-43c4-817d-533d05b5bf25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "# Lets convert the Geography and Gender to categorial.\n",
        "bank_data[\"Geography\"] = bank_data[\"Geography\"].astype('category')\n",
        "bank_data[\"Gender\"] = bank_data[\"Gender\"].astype('category')\n",
        "\n",
        "bank_data[\"Geography\"] = bank_data[\"Geography\"].cat.codes\n",
        "bank_data[\"Gender\"] = bank_data[\"Gender\"].cat.codes\n",
        "\n",
        "bank_data.sample(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5919</th>\n",
              "      <td>645</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>162012.60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>981</th>\n",
              "      <td>749</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>71497.79</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>151083.80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9750</th>\n",
              "      <td>708</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>8</td>\n",
              "      <td>70754.18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>92920.04</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3200</th>\n",
              "      <td>635</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>140197.18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>142935.83</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4892</th>\n",
              "      <td>707</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>10</td>\n",
              "      <td>98438.23</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>70778.63</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7915</th>\n",
              "      <td>695</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>187734.49</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8216</th>\n",
              "      <td>704</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>4</td>\n",
              "      <td>109026.80</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>43117.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6627</th>\n",
              "      <td>558</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>6</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>143585.29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5243</th>\n",
              "      <td>780</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>10</td>\n",
              "      <td>95196.26</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>126310.39</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9558</th>\n",
              "      <td>623</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>4</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5549.11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CreditScore  Geography  Gender  ...  IsActiveMember  EstimatedSalary  Exited\n",
              "5919          645          2       1  ...               0        162012.60       0\n",
              "981           749          1       0  ...               0        151083.80       0\n",
              "9750          708          0       0  ...               1         92920.04       1\n",
              "3200          635          2       1  ...               1        142935.83       0\n",
              "4892          707          1       0  ...               0         70778.63       1\n",
              "7915          695          2       1  ...               0        187734.49       1\n",
              "8216          704          1       1  ...               1         43117.10       0\n",
              "6627          558          0       0  ...               1        143585.29       1\n",
              "5243          780          1       0  ...               0        126310.39       1\n",
              "9558          623          2       1  ...               0          5549.11       1\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umB3azmbEP8J",
        "colab_type": "code",
        "outputId": "2e4c798b-f68d-4f70-c84f-df005deb2ce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "bank_data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 11 columns):\n",
            "CreditScore        10000 non-null int64\n",
            "Geography          10000 non-null int8\n",
            "Gender             10000 non-null int8\n",
            "Age                10000 non-null int64\n",
            "Tenure             10000 non-null int64\n",
            "Balance            10000 non-null float64\n",
            "NumOfProducts      10000 non-null int64\n",
            "HasCrCard          10000 non-null int64\n",
            "IsActiveMember     10000 non-null int64\n",
            "EstimatedSalary    10000 non-null float64\n",
            "Exited             10000 non-null int64\n",
            "dtypes: float64(2), int64(7), int8(2)\n",
            "memory usage: 722.7 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6_-RYWKGMHX",
        "colab_type": "text"
      },
      "source": [
        "###Insights\n",
        "- After dropping the irrelevant features, we are left with 10 features and a target.\n",
        "- Also we have converted the Gender and Geography features to category codes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adGQ3gku9b_U",
        "colab_type": "text"
      },
      "source": [
        "##3. Distinguish the feature and target set (2.5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GxkXEk09fJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Feature set\n",
        "X = bank_data.iloc[:,:-1]\n",
        "#Target set\n",
        "y = bank_data.iloc[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8yNplss9fU4",
        "colab_type": "code",
        "outputId": "dd6e8be2-8f98-46a6-8340-7f77f9f6760f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFDC8XEKGsev",
        "colab_type": "code",
        "outputId": "eb8c1dc9-b839-4ae2-f39d-f24c1e6b443a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore  Geography  Gender  ...  HasCrCard  IsActiveMember  EstimatedSalary\n",
              "0          619          0       0  ...          1               1        101348.88\n",
              "1          608          2       0  ...          0               1        112542.58\n",
              "2          502          0       0  ...          1               0        113931.57\n",
              "3          699          0       0  ...          0               0         93826.63\n",
              "4          850          2       0  ...          1               1         79084.10\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBPQ4MidGzq6",
        "colab_type": "code",
        "outputId": "5ea09894-d3ba-4205-8e25-968cd170f7b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KxAaL_lGw_m",
        "colab_type": "code",
        "outputId": "c8d62bf1-d302-4d27-eb61-6f3e45bb13df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "y.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    0\n",
              "2    1\n",
              "3    0\n",
              "4    0\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX3uT3Cc9fhj",
        "colab_type": "text"
      },
      "source": [
        "##4. Divide the data set into Train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKHzvPVw9j6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpePvtVc9kGm",
        "colab_type": "code",
        "outputId": "89dd2f1a-4587-4cbb-c763-cd9ef0acaeaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUcXuV9yI-yL",
        "colab_type": "code",
        "outputId": "8e5f5ae6-d952-4574-9648-f5ff00235b4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUQGBzK19kD7",
        "colab_type": "code",
        "outputId": "3cfcc501-cc6b-49a7-9563-23b07b201e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbG-Le93JC1V",
        "colab_type": "code",
        "outputId": "75c3fe8c-8316-429c-e619-4c0506532040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdZm1hCzIGqA",
        "colab_type": "code",
        "outputId": "f636d964-ffc8-4cbe-8827-fe04dc4bb4d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3357</th>\n",
              "      <td>658</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>5</td>\n",
              "      <td>75395.53</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>54914.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9793</th>\n",
              "      <td>772</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>101979.16</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>90928.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6002</th>\n",
              "      <td>701</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>47856.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5734</th>\n",
              "      <td>768</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>8</td>\n",
              "      <td>69712.74</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>69381.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>725</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>116803.80</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>124052.97</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CreditScore  Geography  ...  IsActiveMember  EstimatedSalary\n",
              "3357          658          1  ...               1         54914.92\n",
              "9793          772          1  ...               0         90928.48\n",
              "6002          701          0  ...               0         47856.78\n",
              "5734          768          0  ...               1         69381.05\n",
              "241           725          1  ...               0        124052.97\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kU_ByfGaIG3l",
        "colab_type": "code",
        "outputId": "f8da6c22-7d81-41dd-e4dd-e3587bed2745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3357    0\n",
              "9793    0\n",
              "6002    0\n",
              "5734    0\n",
              "241     0\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3AB7ldMIsKo",
        "colab_type": "code",
        "outputId": "7b851649-7f6c-49e7-f345-88d6150b6d2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print \"Unique train labels: \", np.unique(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique train labels:  [0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ilej0knQIyxy",
        "colab_type": "code",
        "outputId": "c20a5254-18b6-4582-f064-ec6f610c4c13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print \"Unique test labels: \", np.unique(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique test labels:  [0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfCpWQSQ9lAY",
        "colab_type": "text"
      },
      "source": [
        "##5. Normalize the train and test data (2.5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vW5ZpCU9oWV",
        "colab_type": "code",
        "outputId": "ccb7a9ba-43d1-4139-d369-d5b0ab82faba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from scipy import stats\n",
        "\n",
        "X_train_Nor = stats.zscore(X_train) \n",
        "X_test_Nor = stats.zscore(X_test)\n",
        "print('Normalization Done')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalization Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF1jWZwULqRY",
        "colab_type": "code",
        "outputId": "c481f047-cee1-4b75-a7cd-3045b0dfb89e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_Nor.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yWQStr19oin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We will have to convert train and test labels into one-hot vectors.\n",
        "y_train_OH = tf.keras.utils.to_categorical(y_train)\n",
        "y_test_OH = tf.keras.utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI0h9yrMLeid",
        "colab_type": "code",
        "outputId": "98b69e20-59e8-4719-9e3a-c7dc9253d83a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "y_train[:20]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3357    0\n",
              "9793    0\n",
              "6002    0\n",
              "5734    0\n",
              "241     0\n",
              "5001    0\n",
              "402     0\n",
              "4101    0\n",
              "870     0\n",
              "9464    0\n",
              "732     0\n",
              "4459    0\n",
              "9719    1\n",
              "5694    0\n",
              "8966    0\n",
              "7406    0\n",
              "46      1\n",
              "3807    0\n",
              "3602    0\n",
              "1493    0\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2e0iqFXN2mS",
        "colab_type": "code",
        "outputId": "5d08bd6c-f9fe-4d81-f342-5caf168d72f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "y_train_OH[:20]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYNs7FWv9o0N",
        "colab_type": "text"
      },
      "source": [
        "##6. Initialize &amp; build the model (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEniph1k1vO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the necessary layers from keras to build the model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlQ4ahMc1x5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a neural Network with a binary crossentropy loss function and sgd optimizer in Keras. The output layer with 2 neurons.\n",
        "\n",
        "#Clear out tensorflow memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Initialize Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "#Add Dense/Input layer\n",
        "model.add(Dense(10, input_dim = 10, activation='relu'))\n",
        "\n",
        "#Add Dense Layer which provides 2 Output after applying sigmoid (Output Layer)\n",
        "model.add(Dense(2, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KCaZ6NJUBOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m219dYkOUBli",
        "colab_type": "text"
      },
      "source": [
        "### Execute the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukhBm3Jg3BdR",
        "colab_type": "code",
        "outputId": "fded87bc-727a-4405-c69a-78524c56e07f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        }
      },
      "source": [
        "#Train the model\n",
        "model.fit(X_train_Nor,y_train_OH, validation_data=(X_test_Nor,y_test_OH), epochs=15, batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/15\n",
            "8000/8000 [==============================] - 2s 208us/sample - loss: 0.5692 - accuracy: 0.7303 - val_loss: 0.4941 - val_accuracy: 0.8035\n",
            "Epoch 2/15\n",
            "8000/8000 [==============================] - 1s 150us/sample - loss: 0.4686 - accuracy: 0.8076 - val_loss: 0.4541 - val_accuracy: 0.8138\n",
            "Epoch 3/15\n",
            "8000/8000 [==============================] - 1s 148us/sample - loss: 0.4421 - accuracy: 0.8142 - val_loss: 0.4384 - val_accuracy: 0.8175\n",
            "Epoch 4/15\n",
            "8000/8000 [==============================] - 1s 150us/sample - loss: 0.4301 - accuracy: 0.8178 - val_loss: 0.4297 - val_accuracy: 0.8223\n",
            "Epoch 5/15\n",
            "8000/8000 [==============================] - 1s 149us/sample - loss: 0.4226 - accuracy: 0.8201 - val_loss: 0.4231 - val_accuracy: 0.8255\n",
            "Epoch 6/15\n",
            "8000/8000 [==============================] - 1s 156us/sample - loss: 0.4163 - accuracy: 0.8228 - val_loss: 0.4172 - val_accuracy: 0.8288\n",
            "Epoch 7/15\n",
            "8000/8000 [==============================] - 1s 149us/sample - loss: 0.4099 - accuracy: 0.8264 - val_loss: 0.4115 - val_accuracy: 0.8313\n",
            "Epoch 8/15\n",
            "8000/8000 [==============================] - 1s 147us/sample - loss: 0.4034 - accuracy: 0.8294 - val_loss: 0.4057 - val_accuracy: 0.8357\n",
            "Epoch 9/15\n",
            "8000/8000 [==============================] - 1s 152us/sample - loss: 0.3964 - accuracy: 0.8360 - val_loss: 0.4000 - val_accuracy: 0.8370\n",
            "Epoch 10/15\n",
            "8000/8000 [==============================] - 1s 150us/sample - loss: 0.3894 - accuracy: 0.8398 - val_loss: 0.3947 - val_accuracy: 0.8395\n",
            "Epoch 11/15\n",
            "8000/8000 [==============================] - 1s 150us/sample - loss: 0.3826 - accuracy: 0.8438 - val_loss: 0.3898 - val_accuracy: 0.8425\n",
            "Epoch 12/15\n",
            "8000/8000 [==============================] - 1s 148us/sample - loss: 0.3770 - accuracy: 0.8476 - val_loss: 0.3859 - val_accuracy: 0.8453\n",
            "Epoch 13/15\n",
            "8000/8000 [==============================] - 1s 155us/sample - loss: 0.3721 - accuracy: 0.8495 - val_loss: 0.3824 - val_accuracy: 0.8460\n",
            "Epoch 14/15\n",
            "8000/8000 [==============================] - 1s 150us/sample - loss: 0.3681 - accuracy: 0.8511 - val_loss: 0.3803 - val_accuracy: 0.8462\n",
            "Epoch 15/15\n",
            "8000/8000 [==============================] - 1s 151us/sample - loss: 0.3646 - accuracy: 0.8526 - val_loss: 0.3779 - val_accuracy: 0.8455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f095c511510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-SKpQzQaB9R",
        "colab_type": "code",
        "outputId": "99e7381f-95aa-4b4c-8d1c-b954a94880a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 132\n",
            "Trainable params: 132\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxYy4l6s9XLr",
        "colab_type": "code",
        "outputId": "3349c2a9-a536-4e94-9ae0-7da6a265bd41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print (\"Final Train Accuracy from model history: \", model.history.history['accuracy'][-1]*100)\n",
        "print (\"Final Test Accuracy from model history: \", model.history.history['val_accuracy'][-1]*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Final Train Accuracy from model history: ', 85.26250123977661)\n",
            "('Final Test Accuracy from model history: ', 84.54999923706055)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtYqS_kW9gpu",
        "colab_type": "code",
        "outputId": "df2f5a0d-de71-4c42-d4ea-c8933be20497",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# list all data in history\n",
        "print(model.history.history.keys())\n",
        "\n",
        "# Summary - History for accuracy\n",
        "plt.plot(model.history.history['accuracy'], color = 'red')\n",
        "plt.plot(model.history.history['val_accuracy'], color = 'green')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Summary - History for loss\n",
        "\n",
        "plt.plot(model.history.history['loss'], color = 'red')\n",
        "plt.plot(model.history.history['val_loss'], color = 'green')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'val_accuracy', 'val_loss', 'accuracy']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFiIiUiaFhYiIlElhISIiZVJYiIhImf4/BpUln5MGMf0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eT-MuXGdYCP",
        "colab_type": "text"
      },
      "source": [
        "### Summary:\n",
        "- As we have binary classification, we have used binary crossentropy for loss and sigmoid for activation in output layer.\n",
        "- We have just tried with relu activation in input layer. We will find the best activation method using grid search.\n",
        "- Same way we have tried with sgd optimizer. We will find the best optimizer using grid search.\n",
        "The test accuracy we have got is 84.5499%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtHlp_Sc9spK",
        "colab_type": "text"
      },
      "source": [
        "##7. Optimize the model (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM2N1ds09vpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.constraints import maxnorm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm2GnRaCfY3I",
        "colab_type": "text"
      },
      "source": [
        "- Lets first findout the best optimizer among 'SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aTkH3KsgT_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setting up optimizers\n",
        "sgd_opt = tf.keras.optimizers.SGD(lr=0.5, decay=1e-6, momentum=0.9, nesterov=True) #sgd_opt can be with momentum, nesterov or without, 2nd choice\n",
        "rmsprop_opt = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9) #almost similar to adadelta\n",
        "adagrad_opt = tf.keras.optimizers.Adagrad(learning_rate=0.01) #solves problem of learning rate 4th choice and 5th choice sgd without momentum\n",
        "adadelta_opt = tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95) #solves problem of learning rate gamma is to be set rho 3rd choice\n",
        "adam_opt = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False) #momentum and adadelta together approach. top choice\n",
        "adamax_opt = tf.keras.optimizers.Adamax(learning_rate=0.002, beta_1=0.9, beta_2=0.999)\n",
        "nadam_opt = tf.keras.optimizers.Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNGuA4V29vzc",
        "colab_type": "code",
        "outputId": "c2b8b1bb-ec08-4650-de43-a48b01d58df3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "#Find out best optimizer\n",
        "\n",
        "#Clear out tensorflow memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "\n",
        "def create_model(optimizer='adam'):\n",
        "  #Initialize Sequential model\n",
        "  model_opt = Sequential()\n",
        "  \n",
        "  #Input Layer\n",
        "  model_opt.add(Dense(10, input_dim = 10, activation='relu'))\n",
        "  \n",
        "  #Add Dense Layer which provides 1 Outputs after applying sigmoid (Output Layer)\n",
        "  model_opt.add(Dense(1, activation='sigmoid'))\n",
        "  \n",
        "  #Compile the model\n",
        "  model_opt.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  return model_opt\n",
        "\n",
        "model_opt = KerasClassifier(build_fn=create_model, epochs=15, batch_size=10, verbose=0)\n",
        "\n",
        "\n",
        "# define the grid search parameters\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "param_grid = dict(optimizer=optimizer)\n",
        "\n",
        "grid = GridSearchCV(estimator=model_opt, param_grid=param_grid, n_jobs=-1, scoring=\"accuracy\", cv=2)\n",
        "grid_result = grid.fit(X_train_Nor, y_train)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.850375 using {'optimizer': 'Nadam'}\n",
            "0.845125 (0.001625) with: {'optimizer': 'SGD'}\n",
            "0.846875 (0.003375) with: {'optimizer': 'RMSprop'}\n",
            "0.780250 (0.003000) with: {'optimizer': 'Adagrad'}\n",
            "0.617875 (0.004625) with: {'optimizer': 'Adadelta'}\n",
            "0.848250 (0.001250) with: {'optimizer': 'Adam'}\n",
            "0.822125 (0.009625) with: {'optimizer': 'Adamax'}\n",
            "0.850375 (0.000125) with: {'optimizer': 'Nadam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5KsH7EhrOyS",
        "colab_type": "text"
      },
      "source": [
        "###From above we can see the best Optimizer is \"Nadam\" with Accuracy of 85.03%, we can see a slight increase in accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zazgku8sLR5",
        "colab_type": "text"
      },
      "source": [
        "Lets find out the best learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdPGtCs9sNtO",
        "colab_type": "code",
        "outputId": "b1fb44a0-fe8d-4bbd-c4f7-e820d7418c14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "#Clear out tensorflow memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Here we will use best optimizer \"Nadam\" to find out best learning rate.\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(learning_rate=0.0001):\n",
        "  #Initialize Sequential model\n",
        "  model_lr = Sequential()\n",
        "  #Input Layer\n",
        "  model_lr.add(Dense(10, input_dim = 10, activation='relu'))\n",
        "  #Add Dense Layer which provides 2 Outputs after applying sigmoid (Output Layer)\n",
        "  model_lr.add(Dense(2, activation='sigmoid'))\n",
        "  #Compile the model\n",
        "  optimizer = Nadam(lr=learning_rate)\n",
        "  model_lr.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "  return model_lr\n",
        "\n",
        "# create model\n",
        "model_lr = KerasClassifier(build_fn=create_model, epochs=15, batch_size=10, verbose=0)\n",
        "\n",
        "# define the grid search parameters\n",
        "learning_rate = [0.001, 0.01, 0.1, 0.2, 0.3, 0.5, 1.0]\n",
        "param_grid = dict(learning_rate=learning_rate)\n",
        "\n",
        "grid = GridSearchCV(estimator=model_lr, param_grid=param_grid, n_jobs=1, cv=2)\n",
        "grid_result = grid.fit(X_train_Nor, y_train_OH)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.854562 using {'learning_rate': 0.01}\n",
            "0.846063 (0.000813) with: {'learning_rate': 0.001}\n",
            "0.854562 (0.002562) with: {'learning_rate': 0.01}\n",
            "0.847000 (0.000750) with: {'learning_rate': 0.1}\n",
            "0.806625 (0.001625) with: {'learning_rate': 0.2}\n",
            "0.795250 (0.003500) with: {'learning_rate': 0.3}\n",
            "0.795625 (0.003875) with: {'learning_rate': 0.5}\n",
            "0.795625 (0.003875) with: {'learning_rate': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvazQl39u99I",
        "colab_type": "text"
      },
      "source": [
        "###So the best learning rate is 0.01 using Nadam as an optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORR5jcvJ5G7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nadam_opt = tf.keras.optimizers.Nadam(learning_rate=0.01, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y3qpnRmvdVV",
        "colab_type": "code",
        "outputId": "6af21544-8750-4368-df4e-0ad61693f67d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "#Clear out tensorflow memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Tune the Neuron Activation Function for hidden layer\n",
        "\n",
        "def create_model(activation='relu'):\n",
        "  #Initialize Sequential model\n",
        "  model_actf = Sequential()\n",
        "  #Input Layer\n",
        "  model_actf.add(Dense(10, input_dim = 10, activation=activation))\n",
        "  #Add Dense Layer which provides 2 Outputs after applying sigmoid (Output Layer)\n",
        "  model_actf.add(Dense(2, activation='sigmoid'))\n",
        "  #Compile the model\n",
        "  model_actf.compile(optimizer=nadam_opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model_actf\n",
        "\n",
        "# create model\n",
        "model_actf = KerasClassifier(build_fn=create_model, epochs=15, batch_size=10, verbose=0)\n",
        "\n",
        "# define the grid search parameters\n",
        "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
        "param_grid = dict(activation=activation)\n",
        "\n",
        "grid = GridSearchCV(estimator=model_actf, param_grid=param_grid, n_jobs=1, cv=2)\n",
        "grid_result = grid.fit(X_train_Nor, y_train_OH)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.860188 using {'activation': 'softmax'}\n",
            "0.860188 (0.002438) with: {'activation': 'softmax'}\n",
            "0.851750 (0.003750) with: {'activation': 'softplus'}\n",
            "0.849125 (0.000250) with: {'activation': 'softsign'}\n",
            "0.854375 (0.003250) with: {'activation': 'relu'}\n",
            "0.850562 (0.000688) with: {'activation': 'tanh'}\n",
            "0.841375 (0.000625) with: {'activation': 'sigmoid'}\n",
            "0.835687 (0.004688) with: {'activation': 'hard_sigmoid'}\n",
            "0.802813 (0.010188) with: {'activation': 'linear'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzW_umNoveVI",
        "colab_type": "text"
      },
      "source": [
        "#### As per above best activation function for hidden layer is \"softmax\" and we can see a slight increase in accuracy also"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKJuKpU4vUXA",
        "colab_type": "code",
        "outputId": "38a22e58-ee1f-4d75-bb21-8614965cd100",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "#Clear out tensorflow memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Tune Network Weight Initialization\n",
        "\n",
        "def create_model(init_mode='uniform'):\n",
        "  #Initialize Sequential model\n",
        "  model_nw = Sequential()\n",
        "  #Input Layer\n",
        "  model_nw.add(Dense(10, input_dim = 10, kernel_initializer = init_mode, activation='softmax'))\n",
        "  #Add Dense Layer which provides 2 Outputs after applying sigmoid (Output Layer)\n",
        "  model_nw.add(Dense(2, kernel_initializer = init_mode, activation='sigmoid'))\n",
        "  #Compile the model\n",
        "  model_nw.compile(optimizer=nadam_opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model_nw\n",
        "\n",
        "# create model\n",
        "model_nw = KerasClassifier(build_fn=create_model, epochs=15, batch_size=10, verbose=0)\n",
        "\n",
        "# define the grid search parameters\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
        "param_grid = dict(init_mode=init_mode)\n",
        "\n",
        "grid = GridSearchCV(estimator=model_nw, param_grid=param_grid, n_jobs=1, cv=2)\n",
        "grid_result = grid.fit(X_train_Nor, y_train_OH)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.859812 using {'init_mode': 'lecun_uniform'}\n",
            "0.858625 (0.000750) with: {'init_mode': 'uniform'}\n",
            "0.859812 (0.000313) with: {'init_mode': 'lecun_uniform'}\n",
            "0.856063 (0.000187) with: {'init_mode': 'normal'}\n",
            "0.795625 (0.003875) with: {'init_mode': 'zero'}\n",
            "0.858813 (0.000188) with: {'init_mode': 'glorot_normal'}\n",
            "0.859375 (0.000500) with: {'init_mode': 'glorot_uniform'}\n",
            "0.858125 (0.003875) with: {'init_mode': 'he_normal'}\n",
            "0.857687 (0.000437) with: {'init_mode': 'he_uniform'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp6FCTN8vWQV",
        "colab_type": "text"
      },
      "source": [
        "####As we can see the best weight initialization is lecun_uniform but the accuracy slightly reduced, so we will not specify activation of initail weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCnNioWJvXIF",
        "colab_type": "code",
        "outputId": "bd2403e3-14cd-4909-88ed-2d42367e1acf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "#Clear out tensorflow memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Tune Dropout Regularization\n",
        "# Tuning the dropout rate for regularization in an effort to limit overfitting and improve the model’s ability to generalize.\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "def create_model(dropout_rate=0.0):\n",
        "  #Initialize Sequential model\n",
        "  model_do = Sequential()\n",
        "  #Input Layer\n",
        "  model_do.add(Dense(10, input_dim = 10, activation='softmax'))\n",
        "  model_do.add(Dropout(dropout_rate))\n",
        "  #Add Dense Layer which provides 2 Outputs after applying sigmoid (Output Layer)\n",
        "  model_do.add(Dense(2, activation='sigmoid'))\n",
        "  #Compile the model\n",
        "  model_do.compile(optimizer=nadam_opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model_do\n",
        "\n",
        "# create model\n",
        "model_do = KerasClassifier(build_fn=create_model, epochs=15, batch_size=10, verbose=0)\n",
        "\n",
        "# define the grid search parameters\n",
        "dropout_rate = [0.0, 0.1, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.75, 0.8, 0.9]\n",
        "param_grid = dict(dropout_rate=dropout_rate)\n",
        "\n",
        "grid = GridSearchCV(estimator=model_do, param_grid=param_grid, n_jobs=1, cv=2)\n",
        "grid_result = grid.fit(X_train_Nor, y_train_OH)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0108 20:52:03.134722 139680191858560 nn_ops.py:4283] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "W0108 20:52:03.252018 139680191858560 nn_ops.py:4283] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "W0108 20:52:04.175364 139680191858560 nn_ops.py:4283] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "W0108 20:52:12.690644 139680191858560 nn_ops.py:4283] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "W0108 20:52:12.797996 139680191858560 nn_ops.py:4283] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.857188 using {'dropout_rate': 0.0}\n",
            "0.857188 (0.000313) with: {'dropout_rate': 0.0}\n",
            "0.855500 (0.001875) with: {'dropout_rate': 0.1}\n",
            "0.855000 (0.004000) with: {'dropout_rate': 0.2}\n",
            "0.853625 (0.004000) with: {'dropout_rate': 0.25}\n",
            "0.855500 (0.005125) with: {'dropout_rate': 0.3}\n",
            "0.845688 (0.009687) with: {'dropout_rate': 0.4}\n",
            "0.836375 (0.000375) with: {'dropout_rate': 0.5}\n",
            "0.810875 (0.007375) with: {'dropout_rate': 0.6}\n",
            "0.795625 (0.003875) with: {'dropout_rate': 0.7}\n",
            "0.795625 (0.003875) with: {'dropout_rate': 0.75}\n",
            "0.795625 (0.003875) with: {'dropout_rate': 0.8}\n",
            "0.795625 (0.003875) with: {'dropout_rate': 0.9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi2EaD9TvvdR",
        "colab_type": "text"
      },
      "source": [
        "#### We can see overall dropout is not contributing to improvement of accuracy of the model, so we will not include dropout in our final model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6cH9Z5Cvu04",
        "colab_type": "code",
        "outputId": "bdd63d16-cb69-4433-b453-7667dcb3678f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "# Tune the Number of Neurons in the Hidden Layer\n",
        "# The number of neurons in a layer is an important parameter to tune. \n",
        "# Generally the number of neurons in a layer controls the representational capacity of the network, at least at that point in the topology.\n",
        "\n",
        "#Clear out tensorflow memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(neurons=1):\n",
        "  #Initialize Sequential model\n",
        "  model_neu = Sequential()\n",
        "  #Input Layer\n",
        "  model_neu.add(Dense(neurons, input_dim = 10, activation='softmax'))\n",
        "  #Add Dense Layer which provides 2 Outputs after applying sigmoid (Output Layer)\n",
        "  model_neu.add(Dense(2, activation='sigmoid'))\n",
        "  #Compile the model\n",
        "  model_neu.compile(optimizer=nadam_opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model_neu\n",
        "\n",
        "# create model\n",
        "model_neu = KerasClassifier(build_fn=create_model, epochs=15, batch_size=10, verbose=0)\n",
        "\n",
        "# define the grid search parameters\n",
        "neurons = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 100]\n",
        "param_grid = dict(neurons=neurons)\n",
        "\n",
        "grid = GridSearchCV(estimator=model_neu, param_grid=param_grid, n_jobs=1, cv=2)\n",
        "grid_result = grid.fit(X_train_Nor, y_train_OH)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.857563 using {'neurons': 40}\n",
            "0.855125 (0.000000) with: {'neurons': 5}\n",
            "0.854875 (0.001125) with: {'neurons': 10}\n",
            "0.854250 (0.000875) with: {'neurons': 15}\n",
            "0.856875 (0.000375) with: {'neurons': 20}\n",
            "0.855625 (0.001000) with: {'neurons': 25}\n",
            "0.855312 (0.000312) with: {'neurons': 30}\n",
            "0.854250 (0.000875) with: {'neurons': 35}\n",
            "0.857563 (0.000937) with: {'neurons': 40}\n",
            "0.855500 (0.000375) with: {'neurons': 45}\n",
            "0.855937 (0.002187) with: {'neurons': 50}\n",
            "0.855875 (0.001375) with: {'neurons': 55}\n",
            "0.855875 (0.001625) with: {'neurons': 60}\n",
            "0.855188 (0.000813) with: {'neurons': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTEUl6yEv2XP",
        "colab_type": "text"
      },
      "source": [
        "####Optimised no. of neuron are 40"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIR6i60Vv2rz",
        "colab_type": "code",
        "outputId": "a296ac48-2732-4714-f41a-d21626175618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        }
      },
      "source": [
        "# Tune Batch Size and Number of Epochs\n",
        "\n",
        "#Clear out tensorflow memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "  #Initialize Sequential model\n",
        "  model_be = Sequential()\n",
        "  \n",
        "  #Input Layer\n",
        "  model_be.add(Dense(40, input_dim = 10, activation='softmax'))\n",
        "     \n",
        "  #Add Dense Layer which provides 1 Outputs after applying sigmoid (Output Layer)\n",
        "  model_be.add(Dense(1, activation='sigmoid'))\n",
        "  \n",
        "  #Compile the model\n",
        "  model_be.compile(optimizer=nadam_opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  return model_be\n",
        "\n",
        "# create model\n",
        "model_be = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "# define the grid search parameters\n",
        "batch_size = [10, 20, 30, 40, 50]\n",
        "epochs = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "grid = GridSearchCV(estimator=model_be, param_grid=param_grid, n_jobs=1, scoring=\"accuracy\", cv=2)\n",
        "grid_result = grid.fit(X_train_Nor, y_train)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.858875 using {'epochs': 90, 'batch_size': 50}\n",
            "0.853875 (0.001375) with: {'epochs': 10, 'batch_size': 10}\n",
            "0.856875 (0.001875) with: {'epochs': 20, 'batch_size': 10}\n",
            "0.856875 (0.001625) with: {'epochs': 30, 'batch_size': 10}\n",
            "0.856875 (0.000625) with: {'epochs': 40, 'batch_size': 10}\n",
            "0.856125 (0.001125) with: {'epochs': 50, 'batch_size': 10}\n",
            "0.853375 (0.002625) with: {'epochs': 60, 'batch_size': 10}\n",
            "0.853750 (0.002750) with: {'epochs': 70, 'batch_size': 10}\n",
            "0.850625 (0.003375) with: {'epochs': 80, 'batch_size': 10}\n",
            "0.852875 (0.002625) with: {'epochs': 90, 'batch_size': 10}\n",
            "0.848750 (0.001000) with: {'epochs': 100, 'batch_size': 10}\n",
            "0.852750 (0.000750) with: {'epochs': 10, 'batch_size': 20}\n",
            "0.858250 (0.001000) with: {'epochs': 20, 'batch_size': 20}\n",
            "0.855875 (0.000125) with: {'epochs': 30, 'batch_size': 20}\n",
            "0.858625 (0.001625) with: {'epochs': 40, 'batch_size': 20}\n",
            "0.855500 (0.001000) with: {'epochs': 50, 'batch_size': 20}\n",
            "0.854750 (0.001500) with: {'epochs': 60, 'batch_size': 20}\n",
            "0.855875 (0.000625) with: {'epochs': 70, 'batch_size': 20}\n",
            "0.857000 (0.002000) with: {'epochs': 80, 'batch_size': 20}\n",
            "0.855000 (0.001000) with: {'epochs': 90, 'batch_size': 20}\n",
            "0.853250 (0.000750) with: {'epochs': 100, 'batch_size': 20}\n",
            "0.852750 (0.001750) with: {'epochs': 10, 'batch_size': 30}\n",
            "0.854500 (0.000750) with: {'epochs': 20, 'batch_size': 30}\n",
            "0.858000 (0.001750) with: {'epochs': 30, 'batch_size': 30}\n",
            "0.857875 (0.000375) with: {'epochs': 40, 'batch_size': 30}\n",
            "0.857250 (0.000250) with: {'epochs': 50, 'batch_size': 30}\n",
            "0.856375 (0.001375) with: {'epochs': 60, 'batch_size': 30}\n",
            "0.851875 (0.003375) with: {'epochs': 70, 'batch_size': 30}\n",
            "0.855500 (0.000500) with: {'epochs': 80, 'batch_size': 30}\n",
            "0.851500 (0.000750) with: {'epochs': 90, 'batch_size': 30}\n",
            "0.855500 (0.003250) with: {'epochs': 100, 'batch_size': 30}\n",
            "0.852000 (0.002000) with: {'epochs': 10, 'batch_size': 40}\n",
            "0.857875 (0.001125) with: {'epochs': 20, 'batch_size': 40}\n",
            "0.855250 (0.000750) with: {'epochs': 30, 'batch_size': 40}\n",
            "0.855500 (0.000250) with: {'epochs': 40, 'batch_size': 40}\n",
            "0.857125 (0.000375) with: {'epochs': 50, 'batch_size': 40}\n",
            "0.858375 (0.000375) with: {'epochs': 60, 'batch_size': 40}\n",
            "0.856375 (0.000375) with: {'epochs': 70, 'batch_size': 40}\n",
            "0.856625 (0.002125) with: {'epochs': 80, 'batch_size': 40}\n",
            "0.854500 (0.000500) with: {'epochs': 90, 'batch_size': 40}\n",
            "0.855625 (0.003375) with: {'epochs': 100, 'batch_size': 40}\n",
            "0.851500 (0.000500) with: {'epochs': 10, 'batch_size': 50}\n",
            "0.856750 (0.000750) with: {'epochs': 20, 'batch_size': 50}\n",
            "0.856375 (0.003875) with: {'epochs': 30, 'batch_size': 50}\n",
            "0.856000 (0.001000) with: {'epochs': 40, 'batch_size': 50}\n",
            "0.857000 (0.000250) with: {'epochs': 50, 'batch_size': 50}\n",
            "0.857750 (0.000000) with: {'epochs': 60, 'batch_size': 50}\n",
            "0.855625 (0.000375) with: {'epochs': 70, 'batch_size': 50}\n",
            "0.856000 (0.002250) with: {'epochs': 80, 'batch_size': 50}\n",
            "0.858875 (0.001125) with: {'epochs': 90, 'batch_size': 50}\n",
            "0.852875 (0.003125) with: {'epochs': 100, 'batch_size': 50}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI-wjIQ3wA9x",
        "colab_type": "text"
      },
      "source": [
        "Number of Epochs & Batch Size = 90,50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Xtb-xBGwB0i",
        "colab_type": "text"
      },
      "source": [
        "###Final hyperparameters for optimization of the model are\n",
        "- Optimizer = 'Nadam'\n",
        "- Learning rate = 0.01\n",
        "- Neuron Activation Function = \"softmax\"\n",
        "- Network Weight Initialization = lecun_uniform \n",
        "- Dropout Regularization p = 0.0\n",
        "- Number of Neurons in the Hidden Layer = 40\n",
        "- Number of Epochs & Batch Size = 90 & 50\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SepQ5kzdwCWU",
        "colab_type": "text"
      },
      "source": [
        "##Final Model Building based on above Optimised Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-5Ru31CwC3k",
        "colab_type": "code",
        "outputId": "00a43bec-2c0a-4f74-e14e-a15e71cac525",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Clear out tensorflow memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#Initialize Sequential model\n",
        "final_model = Sequential()\n",
        "  \n",
        "#Input Layer\n",
        "final_model.add(Dense(10, input_dim = 10, activation='softmax'))\n",
        "\n",
        "#Dense Layer\n",
        "final_model.add(Dense(40, activation='softmax'))\n",
        "\n",
        "#Add Dense Layer which provides 2 Output after applying sigmoid (Output Layer)\n",
        "final_model.add(Dense(2, activation='sigmoid'))\n",
        " \n",
        "#Compile the model\n",
        "final_model.compile(optimizer=nadam_opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        " \n",
        "#Train the model \n",
        "final_model.fit(X_train_Nor, y_train_OH, validation_data=(X_test_Nor, y_test_OH), epochs=90, batch_size=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/90\n",
            "8000/8000 [==============================] - 2s 296us/sample - loss: 0.5186 - accuracy: 0.7912 - val_loss: 0.4726 - val_accuracy: 0.7990\n",
            "Epoch 2/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.4380 - accuracy: 0.7956 - val_loss: 0.4233 - val_accuracy: 0.7990\n",
            "Epoch 3/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3969 - accuracy: 0.8166 - val_loss: 0.3959 - val_accuracy: 0.8455\n",
            "Epoch 4/90\n",
            "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3731 - accuracy: 0.8524 - val_loss: 0.3813 - val_accuracy: 0.8490\n",
            "Epoch 5/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3608 - accuracy: 0.8572 - val_loss: 0.3728 - val_accuracy: 0.8575\n",
            "Epoch 6/90\n",
            "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3545 - accuracy: 0.8578 - val_loss: 0.3692 - val_accuracy: 0.8558\n",
            "Epoch 7/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3510 - accuracy: 0.8611 - val_loss: 0.3683 - val_accuracy: 0.8572\n",
            "Epoch 8/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3483 - accuracy: 0.8606 - val_loss: 0.3651 - val_accuracy: 0.8597\n",
            "Epoch 9/90\n",
            "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3459 - accuracy: 0.8614 - val_loss: 0.3639 - val_accuracy: 0.8580\n",
            "Epoch 10/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3444 - accuracy: 0.8614 - val_loss: 0.3635 - val_accuracy: 0.8595\n",
            "Epoch 11/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3427 - accuracy: 0.8618 - val_loss: 0.3616 - val_accuracy: 0.8575\n",
            "Epoch 12/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3418 - accuracy: 0.8632 - val_loss: 0.3613 - val_accuracy: 0.8602\n",
            "Epoch 13/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3405 - accuracy: 0.8636 - val_loss: 0.3600 - val_accuracy: 0.8600\n",
            "Epoch 14/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3398 - accuracy: 0.8629 - val_loss: 0.3601 - val_accuracy: 0.8602\n",
            "Epoch 15/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3388 - accuracy: 0.8643 - val_loss: 0.3597 - val_accuracy: 0.8602\n",
            "Epoch 16/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3380 - accuracy: 0.8652 - val_loss: 0.3596 - val_accuracy: 0.8600\n",
            "Epoch 17/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3373 - accuracy: 0.8641 - val_loss: 0.3589 - val_accuracy: 0.8587\n",
            "Epoch 18/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3368 - accuracy: 0.8648 - val_loss: 0.3597 - val_accuracy: 0.8570\n",
            "Epoch 19/90\n",
            "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3363 - accuracy: 0.8657 - val_loss: 0.3586 - val_accuracy: 0.8590\n",
            "Epoch 20/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3361 - accuracy: 0.8661 - val_loss: 0.3576 - val_accuracy: 0.8585\n",
            "Epoch 21/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3353 - accuracy: 0.8644 - val_loss: 0.3575 - val_accuracy: 0.8577\n",
            "Epoch 22/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3350 - accuracy: 0.8656 - val_loss: 0.3583 - val_accuracy: 0.8577\n",
            "Epoch 23/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3346 - accuracy: 0.8669 - val_loss: 0.3571 - val_accuracy: 0.8612\n",
            "Epoch 24/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3342 - accuracy: 0.8645 - val_loss: 0.3572 - val_accuracy: 0.8580\n",
            "Epoch 25/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3340 - accuracy: 0.8657 - val_loss: 0.3565 - val_accuracy: 0.8575\n",
            "Epoch 26/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3338 - accuracy: 0.8656 - val_loss: 0.3573 - val_accuracy: 0.8600\n",
            "Epoch 27/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3337 - accuracy: 0.8663 - val_loss: 0.3564 - val_accuracy: 0.8597\n",
            "Epoch 28/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3329 - accuracy: 0.8650 - val_loss: 0.3569 - val_accuracy: 0.8595\n",
            "Epoch 29/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3335 - accuracy: 0.8652 - val_loss: 0.3569 - val_accuracy: 0.8585\n",
            "Epoch 30/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3329 - accuracy: 0.8659 - val_loss: 0.3578 - val_accuracy: 0.8560\n",
            "Epoch 31/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3325 - accuracy: 0.8654 - val_loss: 0.3569 - val_accuracy: 0.8572\n",
            "Epoch 32/90\n",
            "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3323 - accuracy: 0.8650 - val_loss: 0.3561 - val_accuracy: 0.8580\n",
            "Epoch 33/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3321 - accuracy: 0.8666 - val_loss: 0.3579 - val_accuracy: 0.8537\n",
            "Epoch 34/90\n",
            "8000/8000 [==============================] - 0s 44us/sample - loss: 0.3325 - accuracy: 0.8654 - val_loss: 0.3555 - val_accuracy: 0.8568\n",
            "Epoch 35/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3321 - accuracy: 0.8660 - val_loss: 0.3562 - val_accuracy: 0.8553\n",
            "Epoch 36/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3317 - accuracy: 0.8660 - val_loss: 0.3561 - val_accuracy: 0.8595\n",
            "Epoch 37/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3317 - accuracy: 0.8662 - val_loss: 0.3558 - val_accuracy: 0.8585\n",
            "Epoch 38/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3316 - accuracy: 0.8667 - val_loss: 0.3560 - val_accuracy: 0.8572\n",
            "Epoch 39/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3312 - accuracy: 0.8657 - val_loss: 0.3560 - val_accuracy: 0.8595\n",
            "Epoch 40/90\n",
            "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3313 - accuracy: 0.8664 - val_loss: 0.3565 - val_accuracy: 0.8565\n",
            "Epoch 41/90\n",
            "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3314 - accuracy: 0.8652 - val_loss: 0.3562 - val_accuracy: 0.8565\n",
            "Epoch 42/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3310 - accuracy: 0.8654 - val_loss: 0.3556 - val_accuracy: 0.8585\n",
            "Epoch 43/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3309 - accuracy: 0.8664 - val_loss: 0.3552 - val_accuracy: 0.8580\n",
            "Epoch 44/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3307 - accuracy: 0.8656 - val_loss: 0.3558 - val_accuracy: 0.8565\n",
            "Epoch 45/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3309 - accuracy: 0.8653 - val_loss: 0.3557 - val_accuracy: 0.8550\n",
            "Epoch 46/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3303 - accuracy: 0.8661 - val_loss: 0.3556 - val_accuracy: 0.8558\n",
            "Epoch 47/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3303 - accuracy: 0.8660 - val_loss: 0.3552 - val_accuracy: 0.8575\n",
            "Epoch 48/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3302 - accuracy: 0.8671 - val_loss: 0.3559 - val_accuracy: 0.8550\n",
            "Epoch 49/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3301 - accuracy: 0.8659 - val_loss: 0.3553 - val_accuracy: 0.8550\n",
            "Epoch 50/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3298 - accuracy: 0.8664 - val_loss: 0.3556 - val_accuracy: 0.8555\n",
            "Epoch 51/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3299 - accuracy: 0.8663 - val_loss: 0.3558 - val_accuracy: 0.8540\n",
            "Epoch 52/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3300 - accuracy: 0.8663 - val_loss: 0.3554 - val_accuracy: 0.8540\n",
            "Epoch 53/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3298 - accuracy: 0.8662 - val_loss: 0.3560 - val_accuracy: 0.8530\n",
            "Epoch 54/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3298 - accuracy: 0.8669 - val_loss: 0.3551 - val_accuracy: 0.8553\n",
            "Epoch 55/90\n",
            "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3298 - accuracy: 0.8680 - val_loss: 0.3550 - val_accuracy: 0.8555\n",
            "Epoch 56/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3294 - accuracy: 0.8663 - val_loss: 0.3563 - val_accuracy: 0.8520\n",
            "Epoch 57/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3296 - accuracy: 0.8671 - val_loss: 0.3552 - val_accuracy: 0.8540\n",
            "Epoch 58/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3294 - accuracy: 0.8671 - val_loss: 0.3556 - val_accuracy: 0.8530\n",
            "Epoch 59/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3291 - accuracy: 0.8671 - val_loss: 0.3555 - val_accuracy: 0.8530\n",
            "Epoch 60/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3294 - accuracy: 0.8674 - val_loss: 0.3552 - val_accuracy: 0.8547\n",
            "Epoch 61/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3294 - accuracy: 0.8677 - val_loss: 0.3555 - val_accuracy: 0.8565\n",
            "Epoch 62/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3292 - accuracy: 0.8671 - val_loss: 0.3543 - val_accuracy: 0.8550\n",
            "Epoch 63/90\n",
            "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3291 - accuracy: 0.8675 - val_loss: 0.3555 - val_accuracy: 0.8560\n",
            "Epoch 64/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3288 - accuracy: 0.8667 - val_loss: 0.3554 - val_accuracy: 0.8530\n",
            "Epoch 65/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3288 - accuracy: 0.8680 - val_loss: 0.3547 - val_accuracy: 0.8535\n",
            "Epoch 66/90\n",
            "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3289 - accuracy: 0.8687 - val_loss: 0.3540 - val_accuracy: 0.8550\n",
            "Epoch 67/90\n",
            "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3287 - accuracy: 0.8681 - val_loss: 0.3547 - val_accuracy: 0.8530\n",
            "Epoch 68/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3289 - accuracy: 0.8683 - val_loss: 0.3555 - val_accuracy: 0.8543\n",
            "Epoch 69/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3288 - accuracy: 0.8676 - val_loss: 0.3551 - val_accuracy: 0.8520\n",
            "Epoch 70/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3285 - accuracy: 0.8690 - val_loss: 0.3556 - val_accuracy: 0.8555\n",
            "Epoch 71/90\n",
            "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3286 - accuracy: 0.8683 - val_loss: 0.3552 - val_accuracy: 0.8528\n",
            "Epoch 72/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3287 - accuracy: 0.8685 - val_loss: 0.3551 - val_accuracy: 0.8530\n",
            "Epoch 73/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3284 - accuracy: 0.8685 - val_loss: 0.3554 - val_accuracy: 0.8550\n",
            "Epoch 74/90\n",
            "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3284 - accuracy: 0.8663 - val_loss: 0.3544 - val_accuracy: 0.8535\n",
            "Epoch 75/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3284 - accuracy: 0.8679 - val_loss: 0.3561 - val_accuracy: 0.8518\n",
            "Epoch 76/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3282 - accuracy: 0.8687 - val_loss: 0.3569 - val_accuracy: 0.8500\n",
            "Epoch 77/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3284 - accuracy: 0.8673 - val_loss: 0.3553 - val_accuracy: 0.8540\n",
            "Epoch 78/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3283 - accuracy: 0.8686 - val_loss: 0.3557 - val_accuracy: 0.8503\n",
            "Epoch 79/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3282 - accuracy: 0.8678 - val_loss: 0.3550 - val_accuracy: 0.8530\n",
            "Epoch 80/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3282 - accuracy: 0.8677 - val_loss: 0.3554 - val_accuracy: 0.8530\n",
            "Epoch 81/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3284 - accuracy: 0.8676 - val_loss: 0.3551 - val_accuracy: 0.8533\n",
            "Epoch 82/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3281 - accuracy: 0.8681 - val_loss: 0.3546 - val_accuracy: 0.8533\n",
            "Epoch 83/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3281 - accuracy: 0.8687 - val_loss: 0.3557 - val_accuracy: 0.8530\n",
            "Epoch 84/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3280 - accuracy: 0.8684 - val_loss: 0.3550 - val_accuracy: 0.8535\n",
            "Epoch 85/90\n",
            "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3278 - accuracy: 0.8695 - val_loss: 0.3557 - val_accuracy: 0.8500\n",
            "Epoch 86/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3281 - accuracy: 0.8690 - val_loss: 0.3550 - val_accuracy: 0.8520\n",
            "Epoch 87/90\n",
            "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3278 - accuracy: 0.8668 - val_loss: 0.3554 - val_accuracy: 0.8535\n",
            "Epoch 88/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3278 - accuracy: 0.8679 - val_loss: 0.3556 - val_accuracy: 0.8535\n",
            "Epoch 89/90\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.3277 - accuracy: 0.8687 - val_loss: 0.3553 - val_accuracy: 0.8525\n",
            "Epoch 90/90\n",
            "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3278 - accuracy: 0.8687 - val_loss: 0.3552 - val_accuracy: 0.8543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0938d9a6d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTU4jFOFxL9G",
        "colab_type": "code",
        "outputId": "010d9ee2-858b-4dd6-88ad-ab5997b0d9d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "final_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 40)                440       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 82        \n",
            "=================================================================\n",
            "Total params: 632\n",
            "Trainable params: 632\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q6seZR6xOkx",
        "colab_type": "code",
        "outputId": "c0e21851-b258-4924-8cf5-214132e766ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print (\"Final Train Accuracy from model history: \", final_model.history.history['accuracy'][-1]*100)\n",
        "print (\"Final Test Accuracy from model history: \", final_model.history.history['val_accuracy'][-1]*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Final Train Accuracy from model history: ', 86.86875104904175)\n",
            "('Final Test Accuracy from model history: ', 85.42500138282776)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMJXmT-aOvAY",
        "colab_type": "code",
        "outputId": "ce42abe6-c8ce-41be-80b3-a73b69a42a2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "# list all data in history\n",
        "print(final_model.history.history.keys())\n",
        "\n",
        "# Summary - History for accuracy\n",
        "plt.plot(final_model.history.history['accuracy'], color = 'red')\n",
        "plt.plot(final_model.history.history['val_accuracy'], color = 'green')\n",
        "plt.title('Final Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Summary - History for loss\n",
        "\n",
        "plt.plot(final_model.history.history['loss'], color = 'red')\n",
        "plt.plot(final_model.history.history['val_loss'], color = 'green')\n",
        "plt.title('Final Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'val_accuracy', 'val_loss', 'accuracy']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nySIiIrpKsoiIiK6SLCIioqski4iI6Oov8Z22cv2I2ZkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QkilJu29wAp",
        "colab_type": "text"
      },
      "source": [
        "##9. Predict the results using 0.5 as a threshold (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeXxpW5H9zQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make predictions for the testing set without threshold (default threshold is 0.5 for binary classification)\n",
        "y_pred = final_model.predict(X_test_Nor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVC6R5u99zmV",
        "colab_type": "code",
        "outputId": "14fad50c-c0f3-4eb4-cd7f-889c312221fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "print (\"Prediction: \", y_pred[:20])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Prediction: ', array([[0.53733885, 0.46370092],\n",
            "       [0.97356164, 0.02629858],\n",
            "       [0.68313164, 0.31699693],\n",
            "       [0.9383532 , 0.06171945],\n",
            "       [0.9384311 , 0.06214246],\n",
            "       [0.895496  , 0.10472187],\n",
            "       [0.98296857, 0.01693526],\n",
            "       [0.8287723 , 0.17091003],\n",
            "       [0.07778651, 0.92185605],\n",
            "       [0.9762439 , 0.02362847],\n",
            "       [0.97785497, 0.02205616],\n",
            "       [0.8796732 , 0.12058455],\n",
            "       [0.97937274, 0.02051529],\n",
            "       [0.1814045 , 0.81853336],\n",
            "       [0.90623194, 0.09401625],\n",
            "       [0.7131336 , 0.28525165],\n",
            "       [0.9426028 , 0.05718106],\n",
            "       [0.501151  , 0.5001069 ],\n",
            "       [0.86447656, 0.13574877],\n",
            "       [0.8951452 , 0.10516706]], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qww_Ie51WXA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make predictions for the testing set with threshold 0.5\n",
        "y_pred_threshold = (final_model.predict_proba(X_test_Nor) >= 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnY5y4XnWj5x",
        "colab_type": "code",
        "outputId": "b416ffd0-b877-4518-bcef-26431df5e848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "print (\"Prediction: \", y_pred_threshold[:20])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Prediction: ', array([[ True, False],\n",
            "       [ True, False],\n",
            "       [ True, False],\n",
            "       [ True, False],\n",
            "       [ True, False],\n",
            "       [ True, False],\n",
            "       [ True, False],\n",
            "       [ True, False],\n",
            "       [False,  True],\n",
            "       [ True, False],\n",
            "       [ True, False],\n",
            "       [ True, False],\n",
            "       [ True, False],\n",
            "       [False,  True],\n",
            "       [ True, False],\n",
            "       [ True, False],\n",
            "       [ True, False],\n",
            "       [ True,  True],\n",
            "       [ True, False],\n",
            "       [ True, False]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNT43krn90Bk",
        "colab_type": "text"
      },
      "source": [
        "##10. Print the Accuracy score and confusion matrix (2.5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LH7bOu8qW3bw",
        "colab_type": "text"
      },
      "source": [
        "- Accuracy Scores for with and without threshold of 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv_9y6cGXgPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbf8RVbA9vwt",
        "colab_type": "code",
        "outputId": "449b8e50-6dc0-486c-9c90-228ce0f69773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Accuracy score for predictions with & without threshold\n",
        "print \"Accuracy score for predictions without thershold: \", metrics.accuracy_score(y_test_OH, y_pred.round())*100\n",
        "print \"Accuracy score for predictions with threshold of 0.5: \", metrics.accuracy_score(y_test_OH, y_pred_threshold)*100"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score for predictions without thershold:  85.39999999999999\n",
            "Accuracy score for predictions with threshold of 0.5:  85.39999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlslXmgJY18D",
        "colab_type": "text"
      },
      "source": [
        "- Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9A-wz1e9vi6",
        "colab_type": "code",
        "outputId": "64d93108-2e19-4d47-e331-c9db226a0d3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "print (\"Confusion Matrix for predictions without threshold\")\n",
        "pd.DataFrame(metrics.confusion_matrix(y_test_OH.argmax(axis=1), y_pred.argmax(axis=1)),\n",
        "                 columns=['Predicted_Negative', 'Predicted_Negative'], index=['Negative', 'Positive'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix for predictions without threshold\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted_Negative</th>\n",
              "      <th>Predicted_Negative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Negative</th>\n",
              "      <td>1531</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Positive</th>\n",
              "      <td>224</td>\n",
              "      <td>178</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Predicted_Negative  Predicted_Negative\n",
              "Negative                1531                  67\n",
              "Positive                 224                 178"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-Ex-FI3ZrKA",
        "colab_type": "code",
        "outputId": "0993e282-c016-4b53-e1c0-87293d793e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "print (\"Confusion Matrix for predictions with specified threshold of 0.5\")\n",
        "pd.DataFrame(metrics.confusion_matrix(y_test_OH.argmax(axis=1), y_pred_threshold.argmax(axis=1)),\n",
        "                 columns=['Predicted_Negative', 'Predicted_Negative'], index=['Negative', 'Positive'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix for predictions with specified threshold of 0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted_Negative</th>\n",
              "      <th>Predicted_Negative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Negative</th>\n",
              "      <td>1531</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Positive</th>\n",
              "      <td>224</td>\n",
              "      <td>178</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Predicted_Negative  Predicted_Negative\n",
              "Negative                1531                  67\n",
              "Positive                 224                 178"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfYpCjGyabPR",
        "colab_type": "code",
        "outputId": "ff7253a0-b618-4369-a65c-751ac1ef81c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print (\"Classification Report for predictions without threshold\")\n",
        "print(classification_report(y_test_OH, y_pred.round()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report for predictions without threshold\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91      1598\n",
            "           1       0.72      0.44      0.55       402\n",
            "\n",
            "   micro avg       0.85      0.85      0.85      2000\n",
            "   macro avg       0.80      0.70      0.73      2000\n",
            "weighted avg       0.84      0.85      0.84      2000\n",
            " samples avg       0.85      0.85      0.85      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj1C295QanhC",
        "colab_type": "code",
        "outputId": "0bb9bae3-944f-431c-9710-2735bcf98cc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "print (\"Classification Report for predictions with threshold of 0.5\")\n",
        "print(classification_report(y_test_OH, y_pred_threshold))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report for predictions with threshold of 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91      1598\n",
            "           1       0.72      0.44      0.55       402\n",
            "\n",
            "   micro avg       0.85      0.85      0.85      2000\n",
            "   macro avg       0.80      0.70      0.73      2000\n",
            "weighted avg       0.84      0.85      0.84      2000\n",
            " samples avg       0.85      0.85      0.85      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6Ps01c8a_cb",
        "colab_type": "text"
      },
      "source": [
        "##Observations:\n",
        "For binary classification by default the threshold is 0.5. So there is no difference in the accuracy score or classification report with and without specifying the 0.5 threshold."
      ]
    }
  ]
}